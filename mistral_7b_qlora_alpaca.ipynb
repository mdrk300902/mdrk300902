{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdrk300902/mdrk300902/blob/main/mistral_7b_qlora_alpaca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **mistral-7b-qlora-alpaca**\n",
        "This project presents a practical demonstration of instruction‑tuning the Mistral‑7B large language model using QLoRA, a parameter‑efficient fine‑tuning method. By employing 4‑bit quantization, the model can be trained on hardware with limited memory capacity, such as the free Google Colab T4 GPU.\n",
        "\n",
        "The primary objectives are as follows:\n",
        "\n",
        "\n",
        "1.   Showcase a complete, reproducible workflow for adapting a large‑scale model in a resource‑constrained environment.\n",
        "\n",
        "2.   Utilise a small, curated subset of the Alpaca instruction‑following dataset to illustrate the fine‑tuning process from start to finish.\n",
        "\n",
        "3.  Highlight practical skills in data preparation, model optimisation, and deployment‑ready output generation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**The notebook Demonstrates:**\n",
        "\n",
        "* The use of quantisation techniques to load and operate 7‑billion‑parameter\n",
        "models efficiently.\n",
        "\n",
        "* Application of QLoRA via the PEFT framework to update only targeted layers, thereby reducing computational cost.\n",
        "\n",
        "* Integration of Hugging Face’s Trainer API for supervised fine‑tuning with intermediate evaluation and logging.\n",
        "\n",
        "* Best practices for saving LoRA adapters separately, ensuring that the fine‑tuned model remains lightweight and portable for future inference."
      ],
      "metadata": {
        "id": "gsblPsci2NAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check Available GPU Hardware"
      ],
      "metadata": {
        "id": "FK78O-Yt3Qvi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOEsPBMxL9Ld",
        "outputId": "07fd7dc5-0703-4446-8fd7-16be17f0495a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Aug 15 07:23:18 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi || echo \"No NVIDIA GPU detected; this may run on CPU and be very slow.\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manage Dependencies and Install Specific Package Versions"
      ],
      "metadata": {
        "id": "gHRAwzq_4XQS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sAjSGGUDWmMK",
        "outputId": "77e1c9c7-4571-475c-9034-fc41ff2edd61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping triton as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping bitsandbytes as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping transformers as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping accelerate as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping peft as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, which is not installed.\n",
            "fastai 2.7.19 requires torchvision>=0.11, which is not installed.\n",
            "sentence-transformers 5.1.0 requires torch>=1.11.0, which is not installed.\n",
            "sentence-transformers 5.1.0 requires transformers<5.0.0,>=4.41.0, which is not installed.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "f459b09012fc4fa891792ab6486008e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch==2.3.1\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.3.1%2Bcu121-cp311-cp311-linux_x86_64.whl (781.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.0/781.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.3.1 (from torch==2.3.1)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.5.82)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.0%2Bcu121-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m96.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.19.0%2Bcu121-cp311-cp311-linux_x86_64.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.18.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.0%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.4.0%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.3.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.1) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 5.1.0 requires transformers<5.0.0,>=4.41.0, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.3.1+cu121 torchaudio-2.3.1+cu121 torchvision-0.18.1+cu121 triton-2.3.1\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.11/dist-packages (2.3.1)\n",
            "Collecting bitsandbytes==0.43.1\n",
            "  Using cached bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from triton==2.3.1) (3.18.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from bitsandbytes==0.43.1) (2.3.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bitsandbytes==0.43.1) (1.26.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.1) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.1) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->bitsandbytes==0.43.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes==0.43.1) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->bitsandbytes==0.43.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->bitsandbytes==0.43.1) (1.3.0)\n",
            "Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.43.1\n",
            "Collecting transformers==4.43.3\n",
            "  Downloading transformers-4.43.3-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting peft==0.11.1\n",
            "  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting accelerate==0.32.1\n",
            "  Downloading accelerate-0.32.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.43.3) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers==4.43.3) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.43.3) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.43.3) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.43.3) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.43.3) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.43.3) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.43.3) (0.6.2)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.43.3)\n",
            "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.43.3) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.11.1) (2.3.1+cu121)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.43.3) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.43.3) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.43.3) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.43.3) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.43.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.43.3) (2025.8.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft==0.11.1) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.11.1) (12.5.82)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft==0.11.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.13.0->peft==0.11.1) (1.3.0)\n",
            "Downloading transformers-4.43.3-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.11.1-py3-none-any.whl (251 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m118.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers, accelerate, peft\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.4\n",
            "    Uninstalling tokenizers-0.21.4:\n",
            "      Successfully uninstalled tokenizers-0.21.4\n",
            "Successfully installed accelerate-0.32.1 peft-0.11.1 tokenizers-0.19.1 transformers-4.43.3\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y torch torchvision torchaudio triton bitsandbytes transformers accelerate peft numpy\n",
        "!pip install numpy==1.26.4\n",
        "!pip install --index-url https://download.pytorch.org/whl/cu121 torch==2.3.1 torchvision torchaudio\n",
        "!pip install triton==2.3.1 bitsandbytes==0.43.1\n",
        "!pip install transformers==4.43.3 peft==0.11.1 accelerate==0.32.1 datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manage Imports and Verify PyTorch and CUDA Installation"
      ],
      "metadata": {
        "id": "cz9nNPiR4pFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "print(\"Torch:\", torch.__version__, \"CUDA:\", torch.version.cuda)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76Wb6qGTnT9y",
        "outputId": "f322dfbe-f675-47fc-e18e-b9f0a8226c7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch: 2.3.1+cu121 CUDA: 12.1\n",
            "CUDA available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Alpaca Instruction-Following Dataset"
      ],
      "metadata": {
        "id": "6KFrbSkr4q7R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qRNq6zlL-Jv"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"tatsu-lab/alpaca\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install dependencies (Transformers, Datasets, PEFT, Accelerate, BitsAndBytes)"
      ],
      "metadata": {
        "id": "YFKZBMq_401X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsSLXFQ0M0-1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c88aa90a-3093-4d74-d4ce-a889d970f8fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.8 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip -q install --upgrade pip\n",
        "!pip -q install \"transformers>=4.41.0\" \"datasets>=2.18.0\" \"peft>=0.11.0\" \"accelerate>=0.30.0\" bitsandbytes==0.43.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports & Config"
      ],
      "metadata": {
        "id": "9mZw8Snz44jd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqa03hPzPufu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "456a636b-1cef-4b21-8fe3-ad90272e50a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig,\n",
        "    TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, PeftModel\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Model & training parameters/knobs\n",
        "model_id = \"mistralai/Mistral-7B-v0.1\"  # could be switched to newer Mistral if available\n",
        "max_length = 512\n",
        "train_samples = 200\n",
        "eval_samples = 60\n",
        "max_steps = 60\n",
        "grad_accum = 4\n",
        "per_device_bs = 1\n",
        "lr = 2e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Alpaca dataset and sample a small subset"
      ],
      "metadata": {
        "id": "irs6l9Z947k4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzdyYlC8T4hV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3315a87-afd8-4f19-c6cf-1b23664277c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'instruction': 'What would be the best type of exercise for a person who has arthritis?',\n",
              " 'input': '',\n",
              " 'output': 'For someone with arthritis, the best type of exercise would be low-impact activities like yoga, swimming, or walking. These exercises provide the benefits of exercise without exacerbating the symptoms of arthritis.',\n",
              " 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWhat would be the best type of exercise for a person who has arthritis?\\n\\n### Response:\\nFor someone with arthritis, the best type of exercise would be low-impact activities like yoga, swimming, or walking. These exercises provide the benefits of exercise without exacerbating the symptoms of arthritis.'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "dataset = load_dataset(\"tatsu-lab/alpaca\")\n",
        "\n",
        "# Shuffling and selecting small subsets for train/eval to fit free GPU constraints\n",
        "train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(train_samples))\n",
        "eval_dataset  = dataset[\"train\"].shuffle(seed=123).select(range(eval_samples))\n",
        "\n",
        "# Peeking\n",
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Authenticate with Hugging Face"
      ],
      "metadata": {
        "id": "oh-Vz3E75Ih3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwpOlGkFUwFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b59811e-8caa-4baf-f75d-6e58c93278bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m⚠️  Warning: 'huggingface-cli login' is deprecated. Use 'hf auth login' instead.\u001b[0m\n",
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `token1` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `token1`\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build prompt template + tokenize"
      ],
      "metadata": {
        "id": "hXYroUXt5MTG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-ZpiPpzUHwB"
      },
      "outputs": [],
      "source": [
        "# Alpaca has fields: instruction, input, output\n",
        "def build_prompt(example):\n",
        "    instr = example.get(\"instruction\", \"\").strip()\n",
        "    inp   = example.get(\"input\", \"\").strip()\n",
        "    out   = example.get(\"output\", \"\").strip()\n",
        "\n",
        "    if inp:\n",
        "        user = f\"### Instruction:\\n{instr}\\n\\n### Input:\\n{inp}\"\n",
        "    else:\n",
        "        user = f\"### Instruction:\\n{instr}\"\n",
        "    assistant = f\"\\n\\n### Response:\\n{out}\"\n",
        "    return user + assistant\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
        "# Mistral-like models: use EOS as pad\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\"\n",
        "\n",
        "def tokenize(example, tokenizer, max_length=512):\n",
        "    text = build_prompt(example)\n",
        "    toks = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "    # For causal LM with Trainer, labels = input_ids\n",
        "    toks[\"labels\"] = toks[\"input_ids\"].copy()\n",
        "    return toks\n",
        "\n",
        "tokenized_train = train_dataset.map(partial(tokenize, tokenizer=tokenizer, max_length=max_length), batched=False)\n",
        "tokenized_eval  = eval_dataset.map(partial(tokenize, tokenizer=tokenizer, max_length=max_length), batched=False)\n",
        "\n",
        "len(tokenized_train), len(tokenized_eval)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Mistral-7B in 4-bit & apply QLoRA"
      ],
      "metadata": {
        "id": "abb-iTTg5VIc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2GkpcsVUKEt"
      },
      "outputs": [],
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16 if torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8 else torch.float16,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# Typical LoRA on LLaMA/Mistral-style attention (q_proj, v_proj)\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\",\"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        "  )\n",
        "\n",
        "model = get_peft_model(model, lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsiHpkn6U46C",
        "outputId": "6c300940-824c-4201-9d76-5948946c46e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 6,815,744 || all params: 7,248,547,840 || trainable%: 0.0940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data collator for causal LM"
      ],
      "metadata": {
        "id": "mqM4Kl5a5rG5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-gTpYByWUx9"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Train (suitable for free Colab)"
      ],
      "metadata": {
        "id": "_qIJDObS5t88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"./mistral-7b-qlora-alpaca\"\n",
        "logging_steps = 5\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=output_dir,\n",
        "    per_device_train_batch_size=per_device_bs,\n",
        "    per_device_eval_batch_size=per_device_bs,\n",
        "    gradient_accumulation_steps=grad_accum,\n",
        "    learning_rate=lr,\n",
        "    max_steps=max_steps,                 # keeping low for demo;  could be increased if access to better GPUs for better results\n",
        "    warmup_steps=max(2, max_steps//10),\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    fp16=(torch.cuda.is_available() and torch.cuda.get_device_capability()[0] < 8),\n",
        "    bf16=(torch.cuda.is_available() and torch.cuda.get_device_capability()[0] >= 8),\n",
        "    logging_steps=logging_steps,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=logging_steps*2,\n",
        "    save_strategy=\"no\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "train_result = trainer.train()\n",
        "train_result.metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "CtM_QbcBrRg0",
        "outputId": "f2b59e0c-951c-4a6c-a2b5-20a1f34c7d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 07:51, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.560700</td>\n",
              "      <td>1.372365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.181600</td>\n",
              "      <td>1.254735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.276000</td>\n",
              "      <td>1.165920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.146800</td>\n",
              "      <td>1.151133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.105200</td>\n",
              "      <td>1.145649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.067200</td>\n",
              "      <td>1.144474</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train_runtime': 477.122,\n",
              " 'train_samples_per_second': 0.503,\n",
              " 'train_steps_per_second': 0.126,\n",
              " 'total_flos': 5247572587315200.0,\n",
              " 'train_loss': 1.2770819664001465,\n",
              " 'epoch': 1.2}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Quick generation test"
      ],
      "metadata": {
        "id": "zaQ4YLmE50GP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "prompt = \"### Instruction:\\nExplain the concept of overfitting in machine learning.\\n\\n### Response:\\n\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=128,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        do_sample=True\n",
        "    )\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCPDbSb2rRkI",
        "outputId": "3973927e-d0d4-4c6d-a05f-6ec3c2b138c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction:\n",
            "Explain the concept of overfitting in machine learning.\n",
            "\n",
            "### Response:\n",
            "Overfitting is a common problem in machine learning, and it occurs when a model learns too much from the training data and is not able to generalize well to new data. This can lead to poor performance on new data, even though the model performed well on the training data. To prevent overfitting, models need to be trained on a wide range of data and have the ability to generalize to new data. This can be achieved through regularization, which helps to reduce the complexity of the model and prevents it from overfitting.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Save LoRA adapters (recommended for QLoRA)"
      ],
      "metadata": {
        "id": "Ps4FkFS853cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adapters_dir = \"./mistral-7b-qlora-alpaca-adapters\"\n",
        "model.save_pretrained(adapters_dir)\n",
        "tokenizer.save_pretrained(adapters_dir)\n",
        "print(\"Saved LoRA adapters to:\", adapters_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aphDeDoWrRnp",
        "outputId": "fa12a6b1-ed49-425f-82b2-77c432c75649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved LoRA adapters to: ./mistral-7b-qlora-alpaca-adapters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Losses Plotting (Traning & Validation)"
      ],
      "metadata": {
        "id": "wY7JEijasQWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(df_metrics[\"step\"], df_metrics[\"train_loss\"], label=\"Training Loss\", marker=\"o\")\n",
        "plt.plot(df_metrics[\"step\"], df_metrics[\"eval_loss\"], label=\"Validation Loss\", marker=\"o\")\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Loss Curves: Training vs Evaluation\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "bBVeqE9trxX6",
        "outputId": "2ba1a9f3-e4de-48ed-8796-809b232ca053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAflBJREFUeJzt3Xd8U2X7x/HPSdK9WzrZuxRoWYJshLIpQxQUFBC3gLgelZ8DcCGO58GBOFBQERFU9izInjJKgbItLdBFgS5KZ87vj9BIaYGONEnb6/16RcnJyTlX7qbNN/e5z7kVVVVVhBBCCCGqCI2lCxBCCCGEMCUJN0IIIYSoUiTcCCGEEKJKkXAjhBBCiCpFwo0QQgghqhQJN0IIIYSoUiTcCCGEEKJKkXAjhBBCiCpFwo0QQgghqhQJN0KISkNRFKZNm1am59arV49x48aZtJ7qrkePHvTo0cNi+y/P+0FUbRJuhFWZP38+iqKwf/9+S5dSIhERETzyyCPUrl0bOzs7PD09CQ0NZd68eeTn51u6PLMo+Jnd7VavXj1Ll1olnTt37o7t/uGHH1q6xHJZs2aNBBhRajpLFyBEZTV37lyeeeYZfH19efTRR2ncuDHp6els2rSJxx9/nPj4eP7v//7P0mVWuG7duvHzzz8XWvbEE0/Qvn17nnrqKeMyZ2fncu/r+vXr6HRl+7N18uRJNJqq+33u4YcfZsCAAUWWt27d2gLVmM6aNWuYPXt2sQGnPO8HUbXJu0KIMtizZw/PPPMMHTt2ZM2aNbi4uBgfe+GFF9i/fz9Hjx41yb6uXbuGk5OTSbZVERo0aECDBg0KLXvmmWdo0KABjzzyyG2fl5eXh16vx9bWtsT7sre3L3OddnZ2ZX5uZdCmTZs7tndVVJ73g6jaqu7XGFGlHTp0iP79++Pq6oqzszO9evViz549hdbJzc1l+vTpNG7cGHt7e7y8vOjSpQvh4eHGdRISEnjssceoVasWdnZ2+Pv7M2TIEM6dO3fH/U+fPh1FUfjll18KBZsC7dq1M47v2LJlC4qisGXLlkLrFBxOmD9/vnHZuHHjcHZ25uzZswwYMAAXFxdGjx7NxIkTcXZ2JjMzs8i+Hn74Yfz8/AodBlu7di1du3bFyckJFxcXBg4cyLFjxwo9rySvPTU1lRMnTpCamnrH9ribgtf6ySefMGvWLBo2bIidnR1RUVHk5OTw9ttv07ZtW9zc3HBycqJr165s3ry5yHZuHWMxbdo0FEXhzJkzjBs3Dnd3d9zc3HjssceKtNWtY24KDqft3LmTl156CW9vb5ycnBg2bBiXLl0q9Fy9Xs+0adMICAjA0dGR++67j6ioqLuO48nNzcXT05PHHnusyGNpaWnY29vzyiuvGJd98cUXNG/eHEdHRzw8PGjXrh0LFy68S+uWzKBBg4qE0AIdO3akXbt2xvvz5s2jZ8+e+Pj4YGdnR1BQEHPmzLnrPgra9Nbfn+J+B7Zv386DDz5InTp1sLOzo3bt2rz44otcv37duM64ceOYPXs2QKFDbQWKG3NTkr8NpfnZi8pJem5EpXPs2DG6du2Kq6srr776KjY2NnzzzTf06NGDrVu30qFDB8DwwTdjxgzjIZK0tDT279/PwYMH6d27NwDDhw/n2LFjTJo0iXr16pGUlER4eDixsbG3HSOSmZnJpk2b6NatG3Xq1DH568vLy6Nv37506dKFTz75BEdHR+rVq8fs2bNZvXo1Dz74YKFaVq5cybhx49BqtQD8/PPPjB07lr59+zJz5kwyMzOZM2cOXbp04dChQ8bXVZLXvnTpUh577DHmzZtnksG48+bNIysri6eeeso4RiktLY25c+fy8MMP8+STT5Kens73339P37592bdvH61atbrrdkeMGEH9+vWZMWMGBw8eZO7cufj4+DBz5sy7PnfSpEl4eHgwdepUzp07x6xZs5g4cSK//fabcZ0pU6bw0UcfERYWRt++fTl8+DB9+/YlKyvrjtu2sbFh2LBh/Pnnn3zzzTeFeqmWLVtGdnY2Dz30EADfffcdzz//PA888ACTJ08mKyuLyMhI9u7dy6hRo+76OjIzM0lOTi6y3N3dHZ1Ox8iRIxkzZgx///0399xzj/HxmJgY9uzZw8cff2xcNmfOHJo3b87gwYPR6XSsXLmS5557Dr1ez4QJE+5aS0ksWbKEzMxMnn32Wby8vNi3bx9ffPEFFy5cYMmSJQA8/fTTxMXFER4eXuTQZ3FK+rehQEl+9qKSUoWwIvPmzVMB9e+//77tOkOHDlVtbW3Vs2fPGpfFxcWpLi4uardu3YzLQkJC1IEDB952O1evXlUB9eOPPy5VjYcPH1YBdfLkySVaf/PmzSqgbt68udDy6OhoFVDnzZtnXDZ27FgVUF9//fVC6+r1erVmzZrq8OHDCy1fvHixCqjbtm1TVVVV09PTVXd3d/XJJ58stF5CQoLq5uZmXF7S117w87i5xpJwcnJSx44dW+S1urq6qklJSYXWzcvLU7Ozswstu3r1qurr66uOHz++0HJAnTp1qvH+1KlTVaDIesOGDVO9vLwKLatbt26hmgpeW2hoqKrX643LX3zxRVWr1aopKSmqqhraTqfTqUOHDi20vWnTpqlAoW0WZ/369Sqgrly5stDyAQMGqA0aNDDeHzJkiNq8efM7bqs4BW17u9vu3btVVVXV1NRU1c7OTn355ZcLPf+jjz5SFUVRY2JijMsyMzOL7Kdv376F6lVVVe3evbvavXt34/2CNo2Oji60XnG/A8XtY8aMGUVqmTBhgnq7j6pb3w8l/dtQ0p+9qLzksJSoVPLz89mwYQNDhw4t1MXu7+/PqFGj2LFjB2lpaYDhG+uxY8c4ffp0sdtycHDA1taWLVu2cPXq1RLXULD94g5Hmcqzzz5b6L6iKDz44IOsWbOGjIwM4/LffvuNmjVr0qVLFwDCw8NJSUnh4YcfJjk52XjTarV06NDBeKinpK993LhxqKpqslOohw8fjre3d6FlWq3W2KOh1+u5cuUKeXl5tGvXjoMHD5Zou88880yh+127duXy5cvGn9WdPPXUU4UOdXTt2pX8/HxiYmIA2LRpE3l5eTz33HOFnjdp0qQS1dazZ09q1KhRqDfg6tWrhIeHM3LkSOMyd3d3Lly4wN9//12i7Rb3OsLDw4vcgoKCAHB1daV///4sXrwYVVWNz/vtt9+49957C/VCOjg4GP+dmppKcnIy3bt3559//in3Icri9nHt2jWSk5Pp1KkTqqpy6NChUm+vNH8bCtztZy8qLwk3olK5dOkSmZmZNG3atMhjzZo1Q6/Xc/78eQDeeecdUlJSaNKkCS1btuQ///kPkZGRxvXt7OyYOXMma9euxdfXl27duvHRRx+RkJBwxxpcXV0BSE9PN+Er+5dOp6NWrVpFlo8cOZLr16+zYsUKADIyMlizZg0PPvig8Q90QZDr2bMn3t7ehW4bNmwgKSkJKPtrL6/69esXu/zHH38kODjYODbK29ub1atXl/iD9NbDgx4eHgAlCq13e27BB12jRo0Krefp6Wlc9050Oh3Dhw9n+fLlZGdnA/Dnn3+Sm5tbKNy89tprODs70759exo3bsyECRPYuXPnXbdfoHHjxoSGhha5FbxfwfAeOn/+PLt37wbg7NmzHDhwoFAdADt37iQ0NBQnJyfc3d3x9vY2nvlnqnATGxvLuHHj8PT0xNnZGW9vb7p3717mfZTmb0OB8rxvhHWTcCOqrG7dunH27Fl++OEHWrRowdy5c2nTpg1z5841rvPCCy9w6tQpZsyYgb29PW+99RbNmjW74zfHRo0aodPpOHLkSInquPmb4c1udx0cOzu7Yk9Zvvfee6lXrx6LFy8GYOXKlVy/fr3QB5NerwcM426K+xa/fPly47plee3ldfO39QILFixg3LhxNGzYkO+//55169YRHh5Oz549ja/nbgrGG93q5h6KinhuST300EOkp6ezdu1aABYvXkxgYCAhISHGdZo1a8bJkydZtGgRXbp04Y8//qBLly5MnTrVZHWEhYXh6OhofA8tXrwYjUZTaBzX2bNn6dWrF8nJyfz3v/9l9erVhIeH8+KLLwLc8WdS0vd6fn4+vXv3ZvXq1bz22mssW7aM8PBw4+D6kv7cy8scP3thGRJuRKXi7e2No6MjJ0+eLPLYiRMn0Gg01K5d27is4EyVX3/9lfPnzxMcHFzk7IqGDRvy8ssvs2HDBo4ePUpOTg6ffvrpbWtwdHSkZ8+ebNu2rcg3weIUfBtMSUkptLwsXd8jRoxg3bp1pKWl8dtvv1GvXj3uvffeQq8FwMfHp9hv8bdeTba0r70i/P777zRo0IA///yTRx99lL59+xIaGnrXwbrmUrduXQDOnDlTaPnly5dL/A2/W7du+Pv789tvv5GcnMxff/1VpLcEwMnJiZEjRzJv3jxiY2MZOHAg77//vsnawsnJiUGDBrFkyRL0ej2//fYbXbt2JSAgwLjOypUryc7OZsWKFTz99NMMGDCA0NDQYoPprUr6Xj9y5AinTp3i008/5bXXXmPIkCGEhoYWqqPA7QLTrUr7t0FUbRJuRKWi1Wrp06cPy5cvL3S6aWJiIgsXLqRLly7GbvjLly8Xeq6zszONGjUyHhrIzMws8qHRsGFDXFxcjOvcztSpU1FVlUcffbTQGJgCBw4c4McffwQMH45arZZt27YVWuerr74q2Yu+yciRI8nOzubHH39k3bp1jBgxotDjffv2xdXVlQ8++IDc3Nwizy84zbWkr91Up4LfScG355u/Le/du9d46MTSevXqhU6nK3Iq9JdfflnibWg0Gh544AFWrlzJzz//TF5eXpFwc+v71dbWlqCgIFRVLfZnWVYjR44kLi6OuXPncvjw4SJ1FPfzSE1NZd68eXfddkG4vvm9np+fz7fffnvXfaiqymeffVZkmwXXeLo1MN2qNH8bRNUnp4ILq/TDDz+wbt26IssnT57Me++9R3h4OF26dOG5555Dp9PxzTffkJ2dzUcffWRcNygoiB49etC2bVs8PT3Zv38/v//+OxMnTgTg1KlT9OrVixEjRhAUFIROp2Pp0qUkJiYaT8+9nU6dOjF79myee+45AgMDC12heMuWLaxYsYL33nsPADc3Nx588EG++OILFEWhYcOGrFq1yjj+pTTatGlDo0aNeOONN8jOzi7yweTq6sqcOXN49NFHadOmDQ899BDe3t7ExsayevVqOnfuzJdfflni127qU8GLM2jQIP7880+GDRvGwIEDiY6O5uuvvyYoKKjY4Ghuvr6+TJ48mU8//ZTBgwfTr18/Dh8+zNq1a6lRo0aJexZGjhzJF198wdSpU2nZsiXNmjUr9HifPn3w8/Ojc+fO+Pr6cvz4cb788ksGDhxYosHrBw8eZMGCBUWWN2zYkI4dOxrvF1w/6ZVXXkGr1TJ8+PAiddja2hIWFsbTTz9NRkYG3333HT4+PsTHx9+xhubNm3PvvfcyZcoUrly5gqenJ4sWLSIvL6/QeoGBgTRs2JBXXnmFixcv4urqyh9//FFsT1jbtm0BeP755+nbty9arfa2v58l/dsgqgHLnKQlRPEKTtG83e38+fOqqqrqwYMH1b59+6rOzs6qo6Ojet9996m7du0qtK333ntPbd++veru7q46ODiogYGB6vvvv6/m5OSoqqqqycnJ6oQJE9TAwEDVyclJdXNzUzt06KAuXry4xPUeOHBAHTVqlBoQEKDa2NioHh4eaq9evdQff/xRzc/PN6536dIldfjw4aqjo6Pq4eGhPv300+rRo0eLPRXcycnpjvt84403VEBt1KjRbdfZvHmz2rdvX9XNzU21t7dXGzZsqI4bN07dv39/qV67qU8FL+7Uc71er37wwQdq3bp1VTs7O7V169bqqlWr1LFjx6p169YttC63ORX80qVLxdZ98ynJtzsV/NbLDhR32nJeXp761ltvqX5+fqqDg4Pas2dP9fjx46qXl5f6zDPPlKhN9Hq9Wrt2bRVQ33vvvSKPf/PNN2q3bt1ULy8v1c7OTm3YsKH6n//8R01NTb3jdu92Knhxp6qPHj3aeCp0cVasWKEGBwer9vb2ar169dSZM2eqP/zwQ5E2vfVUcFVV1bNnz6qhoaGqnZ2d6uvrq/7f//2fGh4eXqRNo6Ki1NDQUNXZ2VmtUaOG+uSTTxovs3Dz+y0vL0+dNGmS6u3trSqKUui08FvfD6pasr8NpfnZi8pJUVUZOSWEEKWVkpKCh4cH7733Hm+88YalyxFC3ETG3AghxF3cPCVAgVmzZgEUGaQthLA8GXMjhBB38dtvvzF//nwGDBiAs7MzO3bs4Ndff6VPnz507tzZ0uUJIW4h4UYIIe4iODgYnU7HRx99RFpamnGQccGgcSGEdZExN0IIIYSoUmTMjRBCCCGqFAk3QgghhKhSqt2YG71eT1xcHC4uLiW++JYQQgghLEtVVdLT0wkICCh2/r2bVbtwExcXJ/OLCCGEEJXU+fPnqVWr1h3XqXbhpuAy5ufPnzf5PCO5ubls2LCBPn36YGNjY9Jti39JO5uHtLN5SDubj7S1eVRUO6elpVG7du0STUdS7cJNwaEoV1fXCgk3jo6OuLq6yi9OBZJ2Ng9pZ/OQdjYfaWvzqOh2LsmQEhlQLIQQQogqRcKNEEIIIaoUCTdCCCGEqFKq3ZgbIYQQ5Zefn09ubq6lyyiV3NxcdDodWVlZ5OfnW7qcKqs87Wxra3vX07xLQsKNEEKIElNVlYSEBFJSUixdSqmpqoqfnx/nz5+X65xVoPK0s0ajoX79+tja2parBgk3QgghSqwg2Pj4+ODo6FipQoJerycjIwNnZ2eT9A6I4pW1nQsushsfH0+dOnXK9d6ScCOEEKJE8vPzjcHGy8vL0uWUml6vJycnB3t7ewk3Fag87ezt7U1cXBx5eXnlOo1cfrpCCCFKpGCMjaOjo4UrEVVVweGo8o6JknAjhBCiVCrToShRuZjqvSXhxkTy9Sp7o69wIFlhb/QV8vWqpUsSQgghqiUJNyaw7mg8XWb+xSM/7Oen01oe+WE/XWb+xbqj8ZYuTQghRAWoV68es2bNKvH6W7ZsQVGUSnmWWWUk4aac1h2N59kFB4lPzSq0PCE1i2cXHJSAI4QQt8jXq+w+e5nlERfZffZyhfZ0K4pivGm1Wjw8PNBqtcZl06ZNK9N2//77b5566qkSr9+pUyfi4+Nxc3Mr0/5KSkKUgZwtVQ75epXpK6Mo7tdSBRRg+sooegf5odXIMWohhFh3NJ7pK6MKfSH0d7NnalgQ/Vr4m3x/8fH/fsFctGgRb7/9NidOnDCexePs7Gx8XFVV8vPz0enu/tHo7e1dqjpsbW3x8/Mr1XNE2UnPTTnsi75SpMfmZioQn5rFvugr5itKCCGslCV6uv38/Iw3V1dXFEUx3j9x4gQuLi6sXbuWtm3bYmdnx44dOzh79ixDhgzB19cXZ2dn7rnnHjZu3Fhou7cellIUhblz5zJs2DAcHR1p3LgxK1asMD5+a4/K/PnzcXd3Z/369TRr1gxnZ2f69etXKIzl5eXx/PPP4+7ujpeXF6+99hpjx45l6NChZW6Pq1evMmbMGDw8PHB0dKR///6cPn3a+HhMTAxhYWF4eHjg5ORE8+bNWbNmjfG5o0ePxtvbGwcHBxo3bsy8efPKXEtFknBTDknptw82ZVlPCCEqG1VVyczJu+stPSuXqSuO3banG2DaiijSs3JLtD1VNd2hrNdff50PP/yQ48ePExwcTEZGBgMGDGDTpk0cOnSIfv36ERYWRmxs7B23M336dEaMGEFkZCQDBgxg9OjRXLly+y+3mZmZfPLJJ/z8889s27aN2NhYXnnlFePjM2fO5JdffmHevHns3LmTtLQ0li1bVq7XOm7cOPbv38+KFSvYvXs3qqoyYMAA42n+EyZMIDs7m23btnHkyBFmzpxp7N166623iIqKYu3atRw/fpw5c+ZQo0aNctVTUeSwVDn4uNibdD0hhKhsrufmE/T2+nJvRwUS0rJoOW1DidaPeqcvjram+Qh755136N27t/G+p6cnISEhxvvvvvsuS5cuZcWKFUycOPG22xk3bhwPP/wwAB988AGff/45+/bto1+/fsWun5uby9dff03Dhg0BmDhxIu+8847x8S+++IIpU6YwbNgwAL788ktjL0pZnD59mhUrVrBz5046deoEwC+//ELt2rVZtmwZDz74ILGxsQwfPpyWLVsC0KBBA+PzY2Njad26Ne3atQMMvVfWSnpuyqF9fU/83ey53WgaBcOx5Pb1Pc1ZlhBCiFIo+LAukJGRwSuvvEKzZs1wd3fH2dmZ48eP37XnJjg42PhvJycnXF1dSUpKuu36jo6OxmAD4O/vb1w/NTWVxMRE2rdvb3xcq9XStm3bUr22mx0/fhydTkeHDh2My7y8vGjatCnHjx8H4Pnnn+e9996jc+fOTJ06lcjISOO6zz77LIsWLaJVq1a8+uqr7Nq1q8y1VDTpuSkHrUZhalgQzy44iALFdrdODQuSwcRCiCrLwUZL1Dt977revugrjJv3913Xm//YPSX6Quhgoy1RfSXh5ORU6P4rr7xCeHg4n3zyCY0aNcLBwYEHHniAnJycO27n1ukCFEVBr9eXan1THm4riyeeeIK+ffuyevVqNmzYwIwZM/j000+ZNGkS/fv3JyYmhjVr1hAeHk6vXr2YMGECn3zyiUVrLo703JRTvxb+zHmkDX5uhQ892ek0zHmkTYWM/hdCCGuhKAqOtrq73ro29i5RT3fXxt4l2l5FXiV5586djBs3jmHDhtGyZUv8/Pw4d+5che2vOG5ubvj6+vL33/8Gwvz8fA4ePFjmbTZr1oy8vDz27t1rXHb58mVOnjxJUFCQcVnt2rV55pln+PPPP3n55Zf57rvvjI95e3szduxYFixYwKxZs/j222/LXE9Fkp4bE+jXwp/eQX7sPpPE4o17WRGrJS9fT/v6lW9iOSGEqAh36ukuiCnW0tPduHFj/vzzT8LCwlAUhbfeeuuOPTAVZdKkScyYMYNGjRoRGBjIF198wdWrV0sU7I4cOYKLi4vxvqIohISEMGTIEJ588km++eYbXFxceP3116lZsyZDhgwB4IUXXqB///40adKEq1evsnnzZpo1awbA22+/Tdu2bWnevDnZ2dmsWrXK+Ji1kXBjIlqNQof6nlyuqXIm14Wo+HRWH4nn0XvrWro0IYSwCgU93bde58avAq9zUxb//e9/GT9+PJ06daJGjRq89tprpKWlmb2O1157jYSEBMaMGYNWq+Wpp56ib9++aLV3PyTXrVu3Qve1Wi15eXnMmzePyZMnM2jQIHJycujWrRtr1qwxHiLLz89nwoQJXLhwAVdXV/r168f//vc/wHCtnilTpnDu3DkcHBzo2rUrixYtMv0LNwFFtfQBPjNLS0vDzc2N1NRUXF1dTbrt3Nxc1qxZQ4JbEDPWnaJtXQ/+eLaTSfch/m3nAQMGFDlmLUxH2tk8KlM7Z2VlER0dTf369bG3L/tZoPl6lX3RV0hKz8LHxXDShTl6bPR6PWlpabi6uhov4leZ6PV6mjVrxogRI3j33XctXc5tlaed7/QeK83nt/TcVICBLf2Yuf4UB2KuEns5kzpejpYuSQghrIZWo9CxoRy2v5uYmBg2bNhA9+7dyc7O5ssvvyQ6OppRo0ZZujSrV/miayXg62pP50aGCxstj7ho4WqEEEJURhqNhvnz53PPPffQuXNnjhw5wsaNG612nIs1kZ6bCjKkVU22n05macRFJvZsVKEj+4UQQlQ9tWvXZufOnZYuo1KSnpsK0re5L/Y2Gv65dI0jF1MtXY4QQghRbUi4qSAu9jb0DjLMALv0kByaEkIIIcxFwk0FGtY6AICVh+PJyzf/NRKEEEKI6kjCTQXq2tgbTydbkjOy2Xn2sqXLEUIIIaoFCTcVyEarYVCw4aJUy+TQlBBCCGEWEm4q2NDWNQFYfyyBzJw8C1cjhBBCVH0SbipY69ru1PVyJDMnn/CoREuXI4QQogx69OjBCy+8YLxfr149Zs2adcfnKIrCsmXLyr1vU22nOpFwU8EURWFIK0PvjZw1JYQQgD4forfDkd8N/9fnV9iuwsLC6NevX7GPbd++HUVRiIyMLPV2//77b5566qnyllfItGnTaNWqVZHl8fHx9O/f36T7utX8+fNxd3ev0H2Yk1zEzwyGtgrg802n2X46meSMbGo421m6JCGEsIyoFbDuNUiL+3eZawD0mwlBg02+u8cff5zhw4dz4cIFAgICCj02b9482rVrR3BwcKm36+3tbaoS78rPz89s+6oqpOfGDBp4OxNS2518vcqqw3F3f4IQQlRFUStg8ZjCwQYgLd6wPGqFyXc5aNAgvL29mT9/fqHlGRkZLFmyhMcff5zLly/z8MMPU7NmTRwdHWnZsiW//vrrHbd762Gp06dP061bN+zt7QkKCiI8PLzIc1577TWaNGmCo6MjDRo04K233iI3Nxcw9JxMnz6dw4cPoygKiqIYa771sNSRI0fo2bMnDg4OeHl58dRTT5GRkWF8fNy4cQwdOpRPPvkEf39/vLy8mDBhgnFfZREbG8uQIUNwdnbG1dWVESNGkJj471CLw4cPc9999+Hi4oK7uzs9evRg//79gGGOrLCwMDw8PHBycqJ58+asWbOmzLWUhPTcmMnQVgEcPp/C0og4xnWub+lyhBDCNFQVcjPvvp4+H9a+CqjFbQRQDD06DXqARnv37dk4QgmmtdHpdIwZM4b58+czZcoU4/IlS5aQn5/Pww8/TEZGBm3btuW1117D1dWV1atX8+ijj9KwYUPat29/95em13P//ffj6+vL3r17SU1NLTQ+p4CLiwvz588nICCAI0eO8OSTT+Li4sKrr77KyJEjOXr0KOvWrWPjxo0AuLm5FdnGtWvX6Nu3Lx07duTvv/8mKSmJJ554gokTJxYKcJs3b8bf35/Nmzdz5swZRo4cSatWrXjyySfv+nqKe30FwWbr1q3k5eUxYcIERo4cyZYtWwAYPXo0rVu3Zs6cOSiKwu7du42z3E+YMIGcnBy2bduGk5MTUVFRODs7l7qO0pBwYyaDggN4b/VxDp9P4Z9LGTTwrtgfrBBCmEVuJnwQcPf17ko19Oh8WLtkq/9fHNg6lWjV8ePH8/HHH7N161batGkDGA5JDR8+HDc3N9zc3HjllVeM60+aNIn169ezePHiEoWbjRs3cuLECdavX2889PXBBx8UGSfz5ptvGv9dr149XnnlFRYtWsSrr76Kg4MDzs7O6HS6Ox6GWrhwIVlZWfz00084ORle/5dffklYWBgzZ87E19cXAA8PD7788ku0Wi2BgYEMHDiQTZs2lSncbNq0iSNHjhAdHU3t2oafz08//UTz5s35+++/ueeee4iNjeU///kPgYGB6PV6fH19cXV1BQy9PsOHD6dly5YANGjQoNQ1lJYcljITbxc7ujY2zBS+LEIOTQkhhLkEBgbSqVMn5s2bB8CZM2fYvn07jz/+OAD5+fm8++67tGzZEk9PT5ydnVm/fj2xsbEl2v7x48epXbt2oTE9HTt2LLLeb7/9RufOnfHz88PZ2Zk333yzxPu4eV8hISHGYAPQuXNn9Ho9J0+eNC5r3rw5Wu2/PWD+/v4kJSWVal8377N27drGYAMQFBSEu7s7x48fB+Cll17iiSeeIDQ0lJkzZxIdHW1c9/nnn+e9996jc+fOTJ06tUwDuEtLem7MaFjrmmw5eYnlERd5MbSxzBQuhKj8bBwNvSh3E7MLfnng7uuN/h3qdirZfkvh8ccfZ9KkSXzwwQfMnz+fhg0b0r17dwA+/vhjPvvsM2bNmkXLli1xcnLihRdeICcnp1T7uJPdu3czevRopk+fTt++fXFzc2PRokV8+umnJtvHzQoOCRVQFAW9vuKmAZo2bRqjRo1i9erVrFmzhmnTprFw4UKGDx/OE088Qd++fVm9ejUbNmxgxowZfPrpp0yaNKnC6pGeGzPqHeSLo62WmMuZHDqfYulyhBCi/BTFcHjobreGPQ1nRXG7L3UKuNY0rFeS7ZXyy+GIESPQaDT8/vvv/Pzzz4wfP974BXPnzp0MGTKERx55hJCQEBo0aMCpU6dKvO1mzZpx/vx54uPjjcv27NlTaJ1du3ZRt25d3njjDdq1a0fjxo2JiYkptI6trS35+Xc+Lb5Zs2YcPnyYa9euGZft3LkTjUZD06ZNS1xzaRS8vvPnzxuXRUVFkZKSQlBQkHFZkyZNePHFF1m/fj2DBg0qNAaodu3aPPPMM/z555+8/PLLfPfddxVSawEJN2bkaKujb3PDsVSZjkEIUa1otIbTvYGiAefG/X4flmwwcRk4OzszYsQI3nnnHeLj4xk3bpzxscaNGxMeHs6uXbs4fvw4Tz/9dKEzge4mNDSUJk2aMHbsWA4fPsz27dt54403Cq3TuHFjYmNjWbRoEWfPnuXzzz9n6dKlhdapV68e0dHRREREkJycTHZ2dpF9jR49Gnt7e8aOHcvRo0fZvHkzkyZN4tFHHzWOtymr/Px8IiIiCt2OHz9OaGgoLVu2ZPTo0Rw8eJB9+/YxZswYunfvTrt27bh+/ToTJ05ky5YtxMTEsHPnTg4dOkSzZs0AeOGFF1i/fj3R0dEcPHiQzZs3Gx+rKBJuzKxgOoZVkfHkykzhQojqJGgwjPgJXP0LL3cNMCyvgOvc3Gz8+PGkpKTQp0+fQuNj3nzzTdq0aUPfvn3p0aMHfn5+DB06tMTb1Wg0LF26lOvXr9O+fXueeOIJ3n///ULrDB48mBdffJGJEyfSqlUrdu3axVtvvVVoneHDh9OvXz/uu+8+vL29iz0d3dHRkfXr13PlyhXuueceHnjgAXr16sWXX35ZusYoRkZGBq1bty50CwsLQ1EUli9fjoeHB926dSM0NJQGDRrw22+/AaDVarl8+TJjxoyhSZMmPPTQQ4SGhjJt2jTAEJomTJhAs2bN6NevH02aNOGrr74qd713oqiqWtx5eVVWWloabm5upKamGkdym0pubi5r1qxhwIABRY53FsjL13PvjE0kZ+Tww7h29AwsX9KujkrSzqL8pJ3NozK1c1ZWFtHR0dSvXx97e/uyb0ifbxiDk5EIzr6GMTYV1GNTaLd6PWlpabi6uqLRyHf7ilKedr7Te6w0n9/y0zUznVZDWIjhG8PSQ3LWlBCiGtJooX5XaPmA4f9mCDaiepFwYwHDbhyaCo9KICNbZgoXQgghTEnCjQW0rOlGA28nsnL1rD+aYOlyhBBCiCpFwo0FKIrC0BszhS+LkLOmhBBCCFOScGMhBeFm55lkEtOyLFyNEEKUXDU7D0WYkaneWxJuLKSOlyNt63qgV2GlzBQuhKgECs7myswswUSZQpRBwVWhb546oixk+gULGtq6JgdirrIs4iJPdK34icSEEKI8tFot7u7uxjmKHB0dK9U0Mnq9npycHLKysuRU8ApU1nbW6/VcunQJR0dHdLryxROLhptt27bx8ccfc+DAAeLj41m6dOkdL5y0ZcsW7rvvviLL4+Pj7ziLqrUa2NKf6SuOcfRiGqcT02ns62LpkoQQ4o4K/taWdRJGS1JVlevXr+Pg4FCpQlllU5521mg01KlTp9w/H4uGm2vXrhESEsL48eO5//77S/y8kydPFrqAj4+PT0WUV+E8nWzp0dSbjceTWBZxkf/0DbR0SUIIcUeKouDv74+Pjw+5ubmWLqdUcnNz2bZtG926dbP6CyZWZuVpZ1tbW5P0qlk03PTv35/+/fuX+nk+Pj64u7ubviALGNq6JhuPJ7E8Io6XezdFo5FvE0II66fVass9LsLctFoteXl52NvbS7ipQNbQzpXyoGOrVq3w9/end+/e7Ny509LllEtoM1+c7XRcuHqdA7FXLV2OEEIIUelVqgHF/v7+fP3117Rr147s7Gzmzp1Ljx492Lt3L23atCn2OdnZ2YVmVk1LSwMM3Wam7lIt2F5ptqsF+gT58OehOP44cJ5WNWXczd2UpZ1F6Uk7m4e0s/lIW5tHRbVzabZnNRNnKopy1wHFxenevTt16tTh559/LvbxadOmMX369CLLFy5ciKOjY1lKNbmTqQpfRWlx1Kq82y4fXaXsTxNCCCEqTmZmJqNGjSrRxJmVquemOO3bt2fHjh23fXzKlCm89NJLxvtpaWnUrl2bPn36VMis4OHh4fTu3btUxxn76lX++GQbienZODZsR2izyjlA2lzK2s6idKSdzUPa2Xykrc2jotq54MhLSVT6cBMREYG/v/9tH7ezs8POzq7Ichsbmwp7c5d22zbA4FYBfLc9mpVHEugfXLNC6qpqKvJnKP4l7Wwe0s7mI21tHqZu59Jsy6LhJiMjgzNnzhjvR0dHExERgaenJ3Xq1GHKlClcvHiRn376CYBZs2ZRv359mjdvTlZWFnPnzuWvv/5iw4YNlnoJJjO0dU2+2x7NxuNJpF7Pxc1BfvGEEEKIsrBouNm/f3+hi/IVHD4aO3Ys8+fPJz4+ntjYWOPjOTk5vPzyy1y8eBFHR0eCg4PZuHFjsRf2q2yC/F1p4uvMqcQM1h2NZ+Q9dSxdkhBCCFEpWTTc9OjR446TZM2fP7/Q/VdffZVXX321gquyDEVRGNq6Jh+tO8myQ3ESboQQQogykvNyrMjgkAAA9kRfJi7luoWrEUIIISonCTdWpJaHI+3re6KqsEJmChdCCCHKRMKNlRnW2nCm1LJDFy1ciRBCCFE5SbixMgNa+GOr1XAiIZ3j8SU/p18IIYQQBhJurIybow33BXoDsCxCem+EEEKI0pJwY4UKDk2tiIhDr7eK2TGEEEKISkPCjRXq0dQHV3sd8alZ7I2+YulyhBBCiEpFwo0VsrfRMqClYUoJGVgshBBClI6EGys19MahqTVH4snKzbdwNUIIIUTlIeHGSrWv50mAmz3p2Xn8dSLJ0uUIIYQQlYaEGyul0SgMbiXXvBFCCCFKS8KNFSs4a2rzySRSMnMsXI0QQghROUi4sWJN/Vxo5u9Kbr7K6iPxli5HCCGEqBQk3Fi5Ya0Nk2kuPyRzTQkhhBAlIeHGyg0OqYmiwL5zVzh/JdPS5QghhBBWT8KNlfNzs6djAy9AZgoXQgghSkLCTSVQcM2bpYcuoqoyHYMQQghxJxJuKoF+Lfyw02k4k5TBsTiZKVwIIYS4Ewk3lYCrvQ2hzXwBueaNEEIIcTcSbiqJgkNTyw/HkS8zhQshhBC3JeGmkujexBt3RxsupWez62yypcsRQgghrJaEm0rCVqdhoHGmcDlrSgghhLgdCTeVSMF0DOuOxnM9R2YKF0IIIYoj4aYSaVvXg1oeDlzLySf8eKKlyxFCCCGskoSbSkRRFGPvzXI5a0oIIYQoloSbSmZIK0O42XrqEpczsi1cjRBCCGF9JNxUMo18nGlZ0408vcwULoQQQhRHwk0ldPN0DEIIIYQoTMJNJRQW4o9GgUOxKcRcvmbpcoQQQgirIuGmEvJxsadzoxqAXPNGCCGEuJWEm0qq4KypZREyU7gQQghxMwk3lVTf5n442GiJTr7G4Qupli5HCCGEsBoSbiopJzsdvYNkpnAhhBDiVhJuKrGCQ1MrD8eRm6+3cDVCCCGEdZBwU4l1aVwDLydbLl/LYccZmSlcCCGEAAk3lZqNVkNYSAAg0zEIIYQQBSTcVHJDWhnCzfpjiVzLzrNwNUIIIYTlSbip5FrVdqeelyPXc/PZEJVg6XKEEEIIi5NwU8kpinLTdAxyQT8hhBBCwk0VMPTGTOE7Tl/iUrrMFC6EEKJ6k3BTBdSr4USr2u7oVcNp4UIIIUR1JuGmirh5OgYhhBCiOpNwU0UMCvZHq1GIvJDK2UsZli5HCCGEsBgJN1WEl7Md3RobZgqXa94IIYSoziTcVCHGs6ZkpnAhhBDVmISbKqRPkB9OtlrOX7nOwdirli5HCCGEsAgJN1WIg62Wvi38AFgm17wRQghRTUm4qWIKrnmzKjKOnDyZKVwIIUT1I+GmiunU0AtvFzuuZuay7dQlS5cjhBBCmJ2EmypGp9Uw+MZM4UvlmjdCCCGqIQk3VVDBBf02RiWSnpVr4WqEEEII85JwUwU1D3ClobcT2Xl61h2VmcKFEEJULxJuqiBFUWQ6BiGEENWWhJsqasiNs6Z2nb1MQmqWhasRQgghzEfCTRVV29ORdnU9UGWmcCGEENWMhJsqzDgdg8w1JYQQohqxaLjZtm0bYWFhBAQEoCgKy5YtK/Fzd+7ciU6no1WrVhVWX2U3sKU/NlqFqPg0TiWmW7ocIYQQwiwsGm6uXbtGSEgIs2fPLtXzUlJSGDNmDL169aqgyqoGDydbejT1AWCZ9N4IIYSoJiwabvr37897773HsGHDSvW8Z555hlGjRtGxY8cKqqzqKJiOYXlEHHq9zBQuhBCi6tNZuoDSmjdvHv/88w8LFizgvffeu+v62dnZZGdnG++npaUBkJubS26uaS9wV7A9U2+3PLo18sDZTsfFlOvsPptE+3qeli6p3KyxnasiaWfzkHY2H2lr86iodi7N9ipVuDl9+jSvv/4627dvR6crWekzZsxg+vTpRZZv2LABR0dHU5cIQHh4eIVst6yau2rYe0nDlyv38VDDqjOZprW1c1Ul7Wwe0s7mI21tHqZu58zMzBKvW2nCTX5+PqNGjWL69Ok0adKkxM+bMmUKL730kvF+WloatWvXpk+fPri6upq0xtzcXMLDw+nduzc2NjYm3XZ5eP5zhb3z9nMszZZefXpgp6vcJ8lZaztXNdLO5iHtbD7S1uZRUe1ccOSlJCpNuElPT2f//v0cOnSIiRMnAqDX61FVFZ1Ox4YNG+jZs2eR59nZ2WFnZ1dkuY2NTYW9uSty22XRubEPfq72JKRlsePsVfq18LN0SSZhbe1cVUk7m4e0s/lIW5uHqdu5NNuqNF/hXV1dOXLkCBEREcbbM888Q9OmTYmIiKBDhw6WLtFqaTQKQ1oZZgqXs6aEEEJUdRbtucnIyODMmTPG+9HR0URERODp6UmdOnWYMmUKFy9e5KeffkKj0dCiRYtCz/fx8cHe3r7IclHU0NY1+WbbP/x1IonUzFzcHOVbixBCiKrJoj03+/fvp3Xr1rRu3RqAl156idatW/P2228DEB8fT2xsrCVLrDKa+bvS1NeFnHw9a4/GW7ocIYQQosJYNNz06NEDVVWL3ObPnw/A/Pnz2bJly22fP23aNCIiIsxSa1Ug0zEIIYSoDirNmBtRfgXjbvZGX+FiynULVyOEEEJUDAk31UiAuwP3NjBcxG9FhMwULoQQomqScFPNFEzHsPTQBVRVpmMQQghR9Ui4qWb6t/THVqvhVGIGx+NlpnAhhBBVj4SbasbNwYZezW7MFB4hA4uFEEJUPRJuqqGCs6ZWRMSRLzOFCyGEqGIk3FRDPZp642qvIyEti73/XLZ0OUIIIYRJSbgxFX0+SswOal7ZjRKzA/T5lq7otux0WgYGG04Ll2veCCGEqGok3JhC1AqY1QLdgqG0i5mDbsFQmNXCsNxKDbtxaGrt0QSycq03iAkhhBClJeGmvKJWwOIxkHbLdWPS4g3LrTTgtKvrQU13BzKy89h0PMnS5QghhBAmI+GmPPT5sO41oLhBuTeWrXvdKg9R3TxTuByaEkIIUZVIuCmPmF1Fe2wKUSHtomE9K1RwaGrLySSuXsuxcDVCCCGEaUi4KY+MRNOuZ2aNfV1oHuBKnl5l9RGZKVwIIUTVIOGmPJx9TbueBRRMx7BMDk0JIYSoIiTclEfdTuAaACi3X0fnAAFtzFZSaQ1uFYCiwP6Yq8RezrR0OUIIIUS5SbgpD40W+s28cec2ASfvOvwyHDKvmK2s0vB1tadzwxoALJfpGIQQQlQBEm7KK2gwjPgJXP0LL3etCT2mgJ0bxO6GH/rC1RjL1HgXBdMxLIu4KDOFCyGEqPQk3JhC0GB44Sh5jyxjf91nyXtkGbxwBHq8DuPXGYJO8in4vjfERVi62iL6NvfFTqfh7KVrHL2YZulyhBBCiHKRcGMqGi1q3S5c9OyIWreL4ZAVgG8QPLERfFsYzpqaNwBOh1u21lu42NvQO8gw6FmueSOEEKKyk3BjDq4B8NgaqN8dcq/BwpFw8CdLV1VIwTVvVhyOIy9fb+FqhBBCiLKTcGMu9m4w+ncIfgjUfFgxCTbPACsZ49KtiTcejjYkZ2Sz66zMFC6EEKLyknBjTjpbGPY1dH3FcH/rh7B8IuTnWrYuwEarYdCNmcLlmjdCCCEqMwk35qYo0OstGPQ/UDQQscBwmCo73dKVGc+aWncsgcycPAtXI4QQQpSNhBtLaTceHvoVbBzh7CbDQOP0BIuW1KaOO3U8HcnMySc8yjqnjBBCCCHuRsKNJTXtB2NXgWMNSIiEub3h0kmLlaMoCkNbyaEpIYQQlZuEG0ur1RaeCAfPBpAaC9/3gZjdFitnyI1DU9tOJ5OckW2xOoQQQoiyknBjDTwbwOPhUOseyEqBn4bAsWUWKaWhtzMhtdzI16usOhxnkRqEEEKI8pBwYy2casCYFdB0IORnw5JxsPsri5Ty73QMEm6EEEJUPhJurImtI4z8Ge55AlBh/RRYNwX05r2o3qDgALQahYjzKUQnXzPrvoUQQojyknBjbTRaGPAJhE433N/zFfw+DnKzzFaCt4sdXRoZZgqXgcVCCCEqGwk31khRoMsLcP9c0NhA1HL4eShkXjFbCcNkpnAhhBCVlIQbaxb8IDz6J9i5Qexu+KEvXI0xy657B/niYKMl5nImEedTzLJPIYQQwhQk3Fi7+t1g/DpwrQnJp+D73hAXUeG7dbLT0be5YaZwOTQlhBCiMpFwUxn4BsETG8G3BWQkGq5mfHpjhe+24KyplZHx5MpM4UIIISoJCTeVhWsAPLYG6neH3GuwcAQc/LlCd9mlUQ1qONty5VoOO04nV+i+hBBCCFORcFOZ2LvB6N8heCSo+bBiImz5ECpowK/uppnCl8qhKSGEEJWEhJvKRmcLw76Bri8b7m+ZYQg5+bkVsruCs6Y2RCWQkS0zhQshhLB+Em4qI0WBXm/DwP+CooFDC+DXhyA7w+S7Cq7lRoMaTmTl6ll/1LKzlgshhBAlIeGmMrvncXhoIegc4MxGmD8A0hNNugtFUW6ajkEOTQkhhLB+Em4qu6b9YdxqcKwB8Yfh+1C4dMqkuxjSyjDuZueZZJLSzHelZCGEEKIsJNxUBbXawuMbDLOLp8QaroUTs9tkm6/r5USbOu7oVVghM4ULIYSwchJuqgqvhvB4ONS6B7JS4KchcGyZyTY/TA5NCSGEqCTKFG7Onz/PhQsXjPf37dvHCy+8wLfffmuywkQZONWAMSug6UDIz4Yl42D3VybZ9MDgAHQahaMX0ziTlG6SbQohhBAVoUzhZtSoUWzevBmAhIQEevfuzb59+3jjjTd45513TFqgKCVbRxj5M9zzBKDC+imw7v9AX74rDHs62dK9iTcAyw7JoSkhhBDWq0zh5ujRo7Rv3x6AxYsX06JFC3bt2sUvv/zC/PnzTVmfKAuNFgZ8AqHTDff3zIbfH4Pc8g0GHiozhQshhKgEyhRucnNzsbOzA2Djxo0MHjwYgMDAQOLj401XnSg7RYEuL8D9c0FjA1HL4OehkHmlzJsMbeaLs52OC1evcyDmqqkqFUIIIUyqTOGmefPmfP3112zfvp3w8HD69esHQFxcHF5eXiYtUJRT8IPw6J9g5wqxu+GHvnA1pkybcrDV0re5HyDTMQghhLBeZQo3M2fO5JtvvqFHjx48/PDDhISEALBixQrj4SphRep3g/HrwLUmJJ8ynCoef7hMmyo4a2pVZDw5eTJTuBBCCOujK8uTevToQXJyMmlpaXh4eBiXP/XUUzg6OpqsOGFCvs0Np4r/8iAkHYN5A2DEj9AotFSb6djQCx8XO5LSs9lyMok+N3pyhBBCCGtRpp6b69evk52dbQw2MTExzJo1i5MnT+Lj42PSAoUJudWE8WsNPTk5GfDLCMO8VKWg1SjGKxYvj5CzpoQQQlifMoWbIUOG8NNPPwGQkpJChw4d+PTTTxk6dChz5swxaYHCxOzdYPQf0HIEqPmwfAJs+RBKcfbTkFaGQ1PhxxNJy6qY2ciFEEKIsipTuDl48CBdu3YF4Pfff8fX15eYmBh++uknPv/8c5MWKCqAzhbu/xa6vGS4v2UGrJgI+SULKs0DXGns40xOnp51R2SmcCGEENalTOEmMzMTFxcXADZs2MD999+PRqPh3nvvJSambGfiCDNTFAidCgP/C4rGcHjq14cgO6MET/13pnA5a0oIIYS1KVO4adSoEcuWLeP8+fOsX7+ePn36AJCUlISrq6tJCxQV7J7H4aGFoHOAMxth/gBIT7zr0wrG3eyJvkx86vWKrlIIIYQosTKFm7fffptXXnmFevXq0b59ezp27AgYenFat25t0gKFGTTtD+NWg2MNwyni34fCpVN3fEotD0fa1/NEVWGFDCwWQghhRcoUbh544AFiY2PZv38/69evNy7v1asX//vf/0xWnDCjWm3h8Q3g2QBSYg3XwonZfcenyKEpIYQQ1qhM4QbAz8+P1q1bExcXZ5whvH379gQGBpZ4G9u2bSMsLIyAgAAURWHZsmV3XH/Hjh107twZLy8vHBwcCAwMlDBlSl4NDdfCqdkOslLgpyEQtfy2qw9s6Y+tVsOJhHROJKSZr04hhBDiDsoUbvR6Pe+88w5ubm7UrVuXunXr4u7uzrvvvou+FLNPX7t2jZCQEGbPnl2i9Z2cnJg4cSLbtm3j+PHjvPnmm7z55pt8++23ZXkZojhONWDsSmg6APKzYfFY2FP86f1ujjb0aCozhQshhLAuZbpC8RtvvMH333/Phx9+SOfOnQFDr8q0adPIysri/fffL9F2+vfvT//+/Uu839atWxca01OvXj3+/PNPtm/fzlNPPVW6FyFuz9YRRi6ANf+B/d/Dutch9QL0fhc0hfPwsNY12RCVyPKIi7zatykajWKhooUQQgiDMoWbH3/8kblz5xpnAwcIDg6mZs2aPPfccyUON+V16NAhdu3axXvvvXfbdbKzs8nOzjbeT0szHD7Jzc0lN9e0F6Ar2J6pt2sxfT5E41IT7eZ3YPeX6FPOkz94Nujsjat0beiBi72O+NQsdp1JokN9zwovq8q1s5WSdjYPaWfzkbY2j4pq59JsT1HVUlya9gZ7e3siIyNp0qRJoeUnT56kVatWXL9e+lODFUVh6dKlDB069K7r1qpVi0uXLpGXl8e0adN46623brvutGnTmD59epHlCxculHmwSqjWlV20jv0OjZpPslNT9jWYTK7O2fj4r2c17EnS0NFHz0MNZTJNIYQQppeZmcmoUaNITU2962VnyhRuOnToQIcOHYpcjXjSpEns27ePvXv3lnaTpQo30dHRZGRksGfPHl5//XW+/PJLHn744WLXLa7npnbt2iQnJ5v8mjy5ubmEh4fTu3dvbGxsTLptS1PObUP7+1iU7HTUGk3Ie+g3cKsNwN7oKzzyw35c7HXsfrU7djbaCq2lKrezNZF2Ng9pZ/ORtjaPimrntLQ0atSoUaJwU6bDUh999BEDBw5k48aNxmvc7N69m/Pnz7NmzZqybLJU6tevD0DLli1JTExk2rRptw03dnZ22NnZFVluY2NTYW/uity2xTTuBePXwy8PoiSfwmZ+Pxi9BPxD6NTIB383e+JTs9h+9ir9W/qbpaQq2c5WSNrZPKSdzUfa2jxM3c6l2VaZzpbq3r07p06dYtiwYaSkpJCSksL999/PsWPH+Pnnn8uyyTLT6/WFemZEBfJtbjhV3Kc5ZCTCvAFwZiMajWKcTFOueSOEEMLSytRzAxAQEFBk4PDhw4f5/vvvS3xqdkZGBmfOnDHej46OJiIiAk9PT+rUqcOUKVO4ePGicQby2bNnU6dOHeO1dLZt28Ynn3zC888/X9aXIUrLrSaMXwu/PQLR2+CXETD4c4a2HszXW8+y5eQlUjJzcHe0tXSlQgghqqkyhxtT2L9/P/fdd5/x/ksvGWapHjt2LPPnzyc+Pp7Y2Fjj43q9nilTphAdHY1Op6Nhw4bMnDmTp59+2uy1V2v2bjD6D1g+AY4shuUTCOxxkUDfezmRmMGaIwmM6lDH0lUKIYSopiwabnr06MGdxjPPnz+/0P1JkyYxadKkCq5KlIjOFu7/FtxqwY7/wpYP+J//UMK4n2WHLkq4qeTy9Sp7o69wIFnBK/oKHRv5oJVrGAkhKgmLhhtRySkKhE41HKpa8x+axS/jO5toJpybzIWrmdTykFPtK6N1R+OZvjKK+NQsQMtPp/fj72bP1LAg+rUwz2BxIYQoj1KFm/vvv/+Oj6ekpJSnFlFZ3fMEuATA7+O5j8P8prxD+L6aPNb3XktXJkpp3dF4nl1wkFv7UxNSs3h2wUHmPNJGAo4QwuqV6mwpNze3O97q1q3LmDFjKqpWYc0CB8C4VWTZetBSc45+ex5FvXTK0lWJUsjXq0xfGVUk2ADGZdNXRpGvL/WlsYQQwqxK1XMzb968iqpDVAW12pH72HoSvw6jLonkze2NbvRvUEd6cCqDfdFXbhyKKp4KxKdmsS/6Ch0bepmvMCGEKKUyXedGiNtx8W/K7AZziNA3RJedAj8Ohqjlli5LlEBS+u2DTVnWE0IIS5FwI0wutF1zHsp5k63KPZCfDYvHwp45li5L3IW7Y8mu/unjYn/3lYQQwoIk3AiT69HUB3tHZx67Ppn4xqMBFda9DuvfAL1MrGmNziSl88Hq43ddz9VBR3szzPwuhBDlIeFGmJytTsPAlv7o0fCJ7ikInWZ4YPeX8Md4yJXDGtZCVVWW7D9P2Bc7OZmYgYu9YRje7a5ok3Y9j1/2xpivQCGEKAMJN6JCDG1tmGtqfVQi19s/D/d/BxobOLYUfh4GmVcsXKHIyM7jpcWH+c/vkVzPzadLoxpserk7Xz/SBj+3woee/N3s6RPkC8Dby4/x465zFqhYCCFKRi7iJypE2zoe1PJw4MLV62w8nkhYyAhw9jXMSRW7C37oB4/8Du5yJWNLOBaXyqSFh/gn+RpajcJLvZvwbPeGaDQK/Vr40zvIj91nktiwfS99unagYyMfNAp8tP4kc7acZeqKY6iqyrjO9S39UoQQogjpuREVQqNRGHpjpvBlBTOFN+gO49cZLviXfBLmhkL8YQtWWf2oqspPu88x7Ktd/JN8DX83exY9dS8T7muE5qbpFbQahQ71PWlbQ6VDfU+0GgVFUXi1b1Oe69EQgGkro5i3M9pSL0UIIW5Lwo2oMENbBwCw9dQlrlzLMSz0bQ5PbASfIMhIhHkD4MwmC1ZZfaRez+XZBQd5e/kxcvL0hDbzYc3zXbmnXskHCCuKwn/6NmXCfYaAM31lFD/skIAjhLAuEm5EhWnk40KLmq7k6VVWR8b9+4BbTUMPTr2ukJMBC0fAoV8sV2g1cDD2KgM+2866YwnYaBXeGhTEd2Pa4eFkW+ptKYrCK32aMvG+RgC8syqK7yXgCCGsiIQbUaEKDk0tLTg0VcDeDR75E1qOAH0eLH8Otn4Ed5glXpSeXq/yzdazjPh6NxdTrlPH05E/nu3E413qoyhln+VbURRe7tOEST0NAefdVVHM3f6PqcoWQohykXAjKtTgkAA0ChyMTSHm8rXCD+psYdg30OVFw/3N78PK5yE/z/yFVkGXM7IZ/+PfzFh7gjy9yqBgf1Y934XgWu4m2b6iGAYiP38j4Ly3+rgEHCGEVZBwIyqUj6s9nRvVAGB5RFzRFTQaw3VwBn4KigYO/gSLHobsDPMWWsXsPnuZAZ9vZ8vJS9jpNMy4vyVfPNwaV/uSXYW4pBRF4cXeTXi+V2PAEHC+2yYBRwhhWRJuRIW7+awp9XaHne55Akb+AjoHOL0B5g+E9EQzVlk15OtV/hd+itFz95CYlk0jH2eWT+zMw+3rlOsw1J0U9OBMvhFw3l9znG+3na2QfQkhRElIuBEVrm8LP+xtNPyTfI3IC6m3XzFwAIxbBY5eEB8B34dC8mmz1VnZJaRmMeq7PXy26TR6FUa0q8WKiZ0J9HM1y/5fvCngfLDmBN9slYAjhLAMCTeiwjnb6egT5AcUM7D4VrXawePh4FEfUmLh+94Qu8cMVVZum08mMeDz7eyNvoKTrZZZI1vx0QMhONqa9zqdNwecGWtP8LUEHCGEBUi4EWZRcM2bVZFx5OXfZfJMr4aGa+HUbAvXr8KPgyFqueExfT5KzA5qXtmNErMD9PkVXLl1y83XM2PNcR6b9zdXruUQ5O/KykldjNNfWMKLvZvwQqgh4Hy49gRztkjAEUKYl0y/IMyia2NvPJ1sSc7IYceZZHo09bnzE5xqwNhV8Pt4OLUWFo+FVo/AP5vQpcXRDiBmDrgGQL+ZEDTYHC/Dqpy/ksmkXw8RcT4FgLEd6zJlQDPsbbSWLQx4IbQJCgr/23iKmetOoKLyXI9Gli5LCFFNSM+NMAsbrYawYH/gpukY7sbWEUYugHaPAypE/Axpt5xxlRYPi8dA1ArTFmzl1h6JZ8Dn24k4n4KrvY6vH2nD9CEtrCLYFJgc2piXejcB4KN1J5m9+YyFKxJCVBcSboTZGGcKP5bItewSXstGq4P+H4Hd7QbF3jj7at3r1eIQVVZuPm8tO8qzvxwkPSuP1nXcWf18V/q18Ld0acV6vldjXr4RcD5eLwFHCGEeEm6E2bSq7U5dL0eu5+YTHlWK07xjd0N22h1WUCHtIsTsKneN1uyfSxkM+2oXP++JAeDp7g1Y/HRHans6WriyO5vUqzGv9JGAI4QwHwk3wmwURbn9dAx3klHCIFTS9SqhPw9eYNAXOzgen4aXky3zH7uHKf2bYaOtHL/CE3s25j99mwKGgPPlX3KKvxCi4lSOv4yiyig4NLX99CUupWeX7EnOvqZdrxLJzMnjlSWHeWnxYTJz8rm3gSdrJne9+4BsKzThvkbGgPPJhlN8sUkCjhCiYki4EWZVv4YTIbXd0auG08JLpG4nw1lR3OUKu/GHq9S4m+PxaYR9sYPfD1xAo8CLoU345Yl78XW1t3RpZTbhvka82s8QcD4NP8XnEnCEEBVAwo0wu2GtDNe8KfFZUxqt4XRvoGjAuen+hjdgXn+4dKrcNVqSqqr8sjeGobN3cvbSNXxd7Vj45L1MDm2MVlMxUyiY03M9GvFav0AA/ht+is82SsARQpiWhBthdoNCAtBqFA5fSOXspRJOkBk0GEb8BK63nBXkGmBYPmgW2LrA+b3wdRfY8b9KObt4WlYuE389xBtLj5Kdp6dHU2/WPN+Vext4Wbo0k3q2R0Ne728IOP/beIpZGyt3IBVCWBe5iJ8wuxrOdnRrXIPNJy+x/NBFXurTtGRPDBoMgQPJ+2cbEdvX06prX3QNuhl6dgAa94aVk+HMRtg4DY4tg6FfgW/zinopJnX4fAqTfj1E7JVMdBqFV/s15YkuDdBUgd6a4jzTvSEKhmkaZm08jaoarm4shBDlJT03wiIKBhYvi4i7/UzhxdFoUet24aJnR9S6Xf4NNgButWD07zB0Dti7GSbf/KY7bPkQ8nJM+wJMSFVV5m7/hwe+3kXslUxqeTiw5JmOPNWtYZUNNgWe7t6Q/xtg6MH5bNNp/hcuPThCiPKTcCMsoneQL462WmKvZHIwNsV0G1YUaDUKJuyDpgNBnwtbZsB390HcIdPtx0SuXsvhiR/3897q4+Tmq/Rv4cfq57vSuo6HpUszm6e6NeSNAc0AQ8D5b/ip0gVeIYS4hYQbYRGOtjr6NTfMFF7igcWl4eIHD/0CD/wAjl6QeBS+6wUbp0Nulun3Vwb7oq8w4PPtbDqRhK1Ow7tDmvPV6Da4OdhYujSze7JbA94caAg4n9/owZGAI4QoKwk3wmIKDk2tiowj924zhZeFokCL4YZenOb3g5oPO/4L33SF8/tMv78SyterfLHpNA99u5v41Cwa1HBi6XOdeLRjPRSlah+GupMnut4UcP46Iz04Qogyk3AjLKZTQy9qONtxNTOXbacuVdyOnGrAg/MMk3A6+UDyKfi+D6z7P8jJrLj9FiMpPYsxP+zl0/BT6FW4v3VNVk7qQvMAN7PWYa1uDjhf/HWGTzdIwBFClJ6EG2ExOq2GwSGGa96UajqGsmoWBhP2QsgoQIU9s2FOJzi3o+L3jeGqzAM+287OM5dxsNHyyYMh/HdkK5zs5KTFmz3RtQFvDQoC4MvNZ/hkw0kJOEKIUpFwIyxq2I1DU+FRiaRn5Vb8Dh09YdgcGLUEXGvC1WiYPxBWvwzZ6RWyy7x8PR+tO8GYH/aRnJFDoJ8LKyd15oG2tSpkf1XB413qGwPO7M1n+Xi9BBwhRMlJuBEW1aKmKw28ncjO07P+mBknvmzSB57bDW3HGe7/PRe+6ghnNpl0NxdTrjPy2z18teUsqgqjO9Rh2YTONPJxMel+qqLHu9Tn7RsB56stZ/lIAo4QooQk3AiLUhSFYTdmCq+Qs6buxN4Nwj6DMcvBvQ6knocF98PyiXA9pdybD49KZMBn2zkQcxUXOx2zR7Xh/WEtsbfR3v3JAoDxXeozNcwQcOZsOcvMdRJwhBB3J+FGWNyQG+Fm59lkEtMscJp2gx7w7G5o/7Th/qGf4at74eS6Mm0uOy+f6SuP8eRP+0m9nktwLTdWP9+VgcH+d3+yKOKxzvWZdiPgfL31LB+uOyEBRwhxRxJuhMXV8XKkXV0PVBVWRJRwpnBTs3OGAR/BY2vBsyGkx8OvI+GPJyHzSok3cy75GsPn7GLeznMAPNGlPr8/04k6Xo4VVHj1MK5zfaYPNkyj8c3Wf/hwrQQcIcTtSbgRVmGIcToGMx+aulXdTvDsTuj0PCgaOLIYZreHqOV3feqKw3EM+mIHRy+m4e5ow/dj2/HmoCBsdfJrZgpjO9XjnSE3As62f5ghAUcIcRvyV1dYhUEt/dFpFI7FpXEqsWLOWioxGwfo8y48vhG8A+HaJVg8xnDLSCqy+vWcfF7/I5Lnfz1ERnYe7et5snZyV3o187VA8VXbmI71ePdGwPl22z98sOa4BBwhRBESboRV8HCypUdTH8ACA4tvp1ZbeHobdPsPKFpD783sDhC5BG58oJ5OTGfI7B0s+vs8igKTejZi4ZMd8HdzsHDxVdejHevx7tAWAHy3PZr3V0vAEUIUJuFGWI2Ca94sj4hDr7eSDyudHfR8E57aDH4t4foV+PMJ1F8fYuX2/YR9uYNTiRnUcLZjweMdeLlPU3Ra+bWqaI/eW5f3bgScuTuieU8CjhDiJvJXWFiNXs18cLbTcTHlOvtjrlq6nML8Q+DJzXDfm6gaG5RT6+i+MYww/V90beTF2sld6dyohqWrrFYeubcu7w8zBJzvd0Tz7ioJOEIIAwk3wmrY22jp38IwU7hZpmMoLa0NRxs9xWN2nxKhb4CrksnHNt/yk+2HeOeb8QKEwmh0h7p8MKwlAD/sjOadVVEScIQQEm6EdSk4NLU6Mo7svHwLV/MvVVWZvzOa+7/axZarNZhkP5Pz7aaAzh7ln82Gqxv/PRf0FTC7ubijUR3qGAPOvJ3nJOAIISTcCOvSoYEXvq52pGXlseVkBc4UXgqpmbk8/fMBpq2MIidfT2gzX1a+0IPag16HZ3ZCnY6Qk2GYn+rHMLh81tIlVzujOtRhxv3/BpzpKyXgCFGdSbgRVkWrUYxXLLaGs6YOxFxlwOfb2RCViK1Ww9SwIL4b0xZ3R1vDCjUawbg10P8jsHGEmB0wpzPsng166+l5qg4ebl+HD28EnPm7JOAIUZ1JuBFWZ+iNcLPpeBKp180wU3gx9HqVOVvOMuKb3VxMuU5dL0f+eLYTj3Wuj6IohVfWaKDD0/DsLqjfDfKuw/r/gx/6waVTFqm/unqofR1mDm+JokjAEaI6k3AjrE4zfxea+rqQk69n7ZF4s+8/OSObcfP/Zua6E+TrVcJCAlg1qQsta7nd+Yme9WHMCsNknLYucGEffN0Ftv8X8vPMU7xg5D11mHl/sDHgTFtxTAKOENWMhBthdRRFYUjrAMD80zHsOpNM/8+2s+3UJextNHx4f0s+f6gVLvY2JduAokDbcTBhDzTqDfnZsGk6zO0FCUcrtHbxrxH31DYGnB93xzBVAo4Q1YqEG2GVCsbd7PnnChdTrlf4/vLy9fx3w0lGf7+XS+nZNPZxZvmELjzUvk7Rw1Al4VYLRi+BoV+DvRvER8C33WHzDMjLMXn9oqgR99Rm5nBDwPlpdwxvL5eAI0R1IeFGWKWa7g50qO8JVPxM4QmpWYyau5fP/zqDqsLIdrVZMbELTf1cyrdhRYFWD8OEfRA4CPR5sPVD+LYHxB0ySe3izka0q81HNwLOz3tieGv5Ueu5+rUQosJYNNxs27aNsLAwAgICUBSFZcuW3XH9P//8k969e+Pt7Y2rqysdO3Zk/fr15ilWmN2/0zFU3KGpv04k0v+zbeyLvoKTrZbPHmrFzAeCcbDVmm4nLn4wcgE88AM4ekHSMfiuF2ycBrlZptuPKNaD7Wrz8QMhKAos2BMrAUeIasCi4ebatWuEhIQwe/bsEq2/bds2evfuzZo1azhw4AD33XcfYWFhHDok34Krov4t/bHVajiRkM7x+DSTbjsnT8/7q6MYP38/VzNzaVHTldXPdzUeDjM5RYEWww29OC2Gg5oPO/4H33SF8/sqZp/C6IG2tYwB55e9sbwpAUeIKk1nyZ3379+f/v37l3j9WbNmFbr/wQcfsHz5clauXEnr1q1NXJ2wNDcHG3oG+rDuWALLDl2kmb+rSbZ7/komE389xOHzKQCM61SPKQMCsdOZsLfmdpxqGHpwmt8Pq1+C5FPwfR+49znDBJ22jhVfQzX1QNtaKMArvx9m4d5YVBXeH9oCjaYMY6qEEFatUo+50ev1pKen4+npaelSRAUZetNM4fkm+Ka95kg8Az7fzuHzKbg52PDNo22ZNri5eYLNzZoNguf2QMgoQIU9s2FOJ4jebt46qpnhbWvx6YOGHpxf98XyxrIj0oMjRBVk0Z6b8vrkk0/IyMhgxIgRt10nOzub7Oxs4/20NMPhjdzcXHJzTXuBuILtmXq71VmXhh642utISMti1+kk7m3gWaZ2zs7N54N1J1m47wIAbeq4878HWxLg7mC5n5eNCwz6HCVwMNo1L6FcjYYfB5Hf5jH0Pd8Gu3IOaC6nqvp+Dmvpiz6/Ba/+eZRf950nP1/Pu4ODLNaDU1Xb2RpJW5tHRbVzabanqFZybqSiKCxdupShQ4eWaP2FCxfy5JNPsnz5ckJDQ2+73rRp05g+fXqxz3d0lEMAlcGisxp2J2no4K1nVKPST0yZeB3mn9ISl2n48AqtqWdALT1aK+q31OVfJ+jiIupf3gxApo0XEXXGc8m1pYUrq7r2X1JYcEaDikJHHz0jGuiRI1RCWK/MzExGjRpFamoqrq53HqZQKcPNokWLGD9+PEuWLGHgwIF3XLe4npvatWuTnJx818YprdzcXMLDw+nduzc2NiW86Ju4q33nrjD6+/042+nY/Vp3tOhL3M5LD8UxbdVxMnPy8XKy5eMHWtC1UQ0zVV56SvQ2tGteREmJAUAfMpr80HcM18oxs+rwfl5xOJ7//HEEvQoPtq3JexbowakO7WwtpK3No6LaOS0tjRo1apQo3FS6w1K//vor48ePZ9GiRXcNNgB2dnbY2dkVWW5jY1Nhb+6K3HZ11LGhDzXdHbiYcp1tZ67Sp5khnNypna9l5/HW8qP8edBwGnmnhl7MGtkKH1d7s9VdJk16Qd1d8Ne7sPcbNId/QfPPXzDof9C05IPvTakqv5+Ht6uDTqflxd8iWHLgIoqi8OH9wRY5RFWV29naSFubh6nbuTTbsmjHfEZGBhEREURERAAQHR1NREQEsbGxAEyZMoUxY8YY11+4cCFjxozh008/pUOHDiQkJJCQkEBqaqolyhdmotEoDG5V8ukYjsenEfblDv48eBGNAi/3bsLPj3ew/mBTwM4Z+s+Ex9aCVyNIj4dfH4I/noDMK5aursoZ0qom/xvZCo0Ci/df4LU/ImWQsRCVnEXDzf79+2ndurXxNO6XXnqJ1q1b8/bbbwMQHx9vDDoA3377LXl5eUyYMAF/f3/jbfLkyRapX5hPwQX9tpxM4mpm8dMXqKrKgj0xDJm9k38uXcPP1Z5fn7yXSb0ao62MgynqdoRndkDnyaBo4MgSmN0eji2zdGVVzpBWNZn1UGs0Ciw5cIFX/4g0ydl5QgjLsOhhqR49etxxrpf58+cXur9ly5aKLUhYrSa+LgT5uxIVn8bao4m43/J46vVcpvwZyZojCQD0DPThkwdD8HSyNXutJmXjAL3fgWZDYPkEuHQcloyFo4Nh4Kfg7GPpCquMwSEBKMALv0Xw+4ELqCp89EBw5QzGQlRzVnS+iBB3VtB788u+WA4kK+yNvkK+XiXifAoDP9/OmiMJ2GgV3hzYjO/Htqv8weZmtdrC01uh26ug0cHxFYZenMO/gXWcE1AlhIUE8NlDrdBqFP44eIH//H5YenCEqIQq3YBiUX052xverqcSr3EqUctPp/fjYq/jWnYeehVqezrwxcNtaFXb3bKFVhSdHfR8A5qFwfLnIOEILH0Kjv1pGHDsGmDpCquEQcEBKCg8v+iQYUC6Ch8/GCI9OEJUItJzIyqFdUfj+b8/jxRZnp5lCDZt6riz+vmuVTfY3Mw/GJ7cbJiuQWsLp9bB7A5w8CfpxTGRgcH+fP5Qa7QahT8PXeQ/S6QHR4jKRMKNsHr5epXpK6O400dLfGoWTrbVqCNSawPd/gNPb4OabSE7DVZMgp+HwtUYS1dXJQwM9ueLh/8NOK9IwBGi0pBwI6zevugrxKdm3XGd+NQs9kVXw9OkfZrB4+HQ+13Q2cM/WwxzVO37DvSlv5qzKGxAy38DztJDF3l5cYQEHCEqAQk3wuolpd852JR2vSpHo4XOz8MzO6FOR8jJgDWvwI+D4PJZS1dX6Q1o6c+XD7dGp1FYFhHHS4sjyMuX4CiENZNwI6yej0vJLr5X0vWqrBqNYNwa6P8x2DhBzE6Y0xl2zwZ9vqWrq9T6t/Tny1GGgLM8Io6XlxyWgCOEFZNwI6xe+/qe+LvZc7tzVRTA382e9vU9zVmWddJooMNT8NwuqN8N8q7D+v+DH/rCpZOWrq5S69fCny9HtTEGnJcWS8ARwlpJuBFWT6tRmBoWBFAk4BTcnxoWJKfq3syjHoxZAWGfga0LXPgbvu4C2z+F/DxLV1dp9WvhZww4Kw7H8aIEHCGskoQbUSn0a+HPnEfa4OdW+NCTn5s9cx5pQ78W/haqzIopCrQdBxP2QKPekJ8Dm96BuT0N18gRZdKvhR+zRxsCzkoJOEJYJQk3otLo18KfHa/1ZMH4doxpnM+C8e3Y8VpPCTZ341YLRi+BYd+AvTvEH4Zve8DmGZBX/Dxd4s76Nvfjq9FtsNEaAs4Lv8kgYyGsiYQbUaloNQod6nvStoZKh/qeciiqpBQFQh6CCfsgcBDo82Drh4aQc/GgpaurlPo09+Or0W2x0SqsioxnsgQcIayGhBshqhMXXxi5AB6YB45ekHQM5vaC8KmQW01PpS+H3kG+zLkRcFZHxjN5UQS5EnCEsDgJN0JUN4oCLe439OK0eABUPeycZRhwHLvXsI4+HyVmBzWv7EaJ2SGnkt9B6M0B50g8kxcdkoAjhIVJuBGiunKqAQ98Dw8tBGdfuHzacMr4whHwv+boFgylXcwcdAuGwqwWELXC0hVbrdAgX75+pC22Wg1rjiTw/K8ScISwJAk3QlR3gQNhwl5oNRpQ4dR6SI8vvE5aPCweIwHnDno18+XrR9tgq9Ww9qgEHCEsScKNEAIcPGDwF4ZxOMVSDbfVL0HSCci4BPm55qywUugZ6Ms3j7Y1BpxJCyXgCGEJ1WgaZSHEHcXsgszLd17n2iX4qsO/922dDcHIwd1wmnnBvx08DLfbLbNzMYz9qYLuC/Thm0fb8vTPB1h3LIGJCw/yxcNtsNXJd0khzEXCjRDCICOxZOvZOEDudcO/czIMt9TzpduXov038BgDkEfJlulsS7cvC7gv0IdvxhgCzvpjiUxceJAvR0nAEcJcJNwIIQycfUu23qglULcTZKXC9atwPQWybvz/+k3/z7rlfsEtPxvUfEMv0d16iopj43RL4HEvWTCyczXMvWUm9zX14dtH2/LUzwfYEJXIhIUHmX1rwCl0VporNOhmmOVdCFEuEm6EEAZ1O4FrgGHwMGoxKyiGx+t2MnwAO3oabqWVe71w4CkuBBW7LNVQV+41wy3tYun2q2gKh6HS9BjZlG3G+R43BZzwWwNO1ApY9xq6tDjaAcTMMbRvv5kQNLhM+xNCGEi4EUIYaLSGD9bFYzBMSXpzwLkxPqbfh+XvWbBxMNxcSzlthl4P2al3DkFZKcX3IOVmGq7nc/2K4VZaOofbhCD3OwcjOzd6NPXhuzHtePKn/YRHJfLcLweZ0/YiNr+PpUiILDgrbcRPEnCEKAcJN0KIfwUNNnywrnsN0uL+Xe4aYAg2lvzA1Wj+DQ/UL91zc7MKBx9jKCruMNoty1Q95F2H9OuQHneHnRRHAXs3ujt4sN/HmcPJCilnHMg/dxgdapFZ7o1hZ81/oF4XsHeTw1RClIGEGyFEYUGDIXAgef9sI2L7elp17Yuuso8FsbEHGz9w8Svd8/R6yEkvWQi6tcco9xqgGh7LSsEV6Fow3Ka4o343y0iAj24EOJ0D2DkbzkyzcwZbl1vu3/JvO5eb7jsVXt/W2azjjqyKjG+qViTcCCGK0mhR63bh4rE0Qup2qb4fAhqNoffE3g08SvncvJxiD5slRqzFN3pZKbZz3XC7dqmUBdyGjdNNYcfpljB0UziydbpNmHL5NzjZOFWOsCTjm6odCTdCCFERdLbg7GO43cTXtSaUJNw8shT8Qww9R9k3Trkv+L/x33d67JZ11BvzgxUMyKaEp/7fkXKjd+jWcFTcshL0NNk4mv76R1Erbowjk/FNZmElPWQSboQQwozya3ckGS+81ctoivkc16uQpHjhXa8bWp0OnG531ehSUFXIy4Kca5CdfksAuvn+tWIC0033c679u0zVA+q/gSqj/GUawpJz0cNudzrUdmtv0s3ra20N48eKPQ6oGva37nXDFCTVtXfSlKyoh0zCjRBCmNG+mFTm5zzKHJtZ6FUKBRz9jc/gqTmPMi4mlY4NTRBswNAbUnCWmlON8m9PVQ2n9N8cjm4OPsWGo2vFhKmb/l8wxUdOuuFmEhrgTtNfqIZLCvzQz9DDptGCRme4Kdob9++wTCl47NZlNy835zILHiK0sh4yCTdCCGFGSelZrNe359ncF5hq8xMB/HtqegJeTM99lPX69sSvjeLJrg3p1cwHR1sr+1OtKGDraLjdctitTFTVcLp+sb1Jtx5qu004uvXfwJ2DzU0u7Cv/a7AKSglCkObfsFYQypRb1inRspv2oWjg8EKsqYfMyn5jhBCiavNxMVwQcL2+PeHZ7WivOYEPKSThzj59IPob8xlHXkhj0q+HsLfR0CvQl4HB/tzX1AcH2yp4+EQpGLvjBJTwStl3otcbxhWd2QRLxt59/Y6TwKsB6PNBn/fv/9X8Ui4rWJ5nOGx38zrFLsu/8dw7Lbt5Hze2c1sq6HMNN6tyo4csZhfU72qWPUq4EUIIM2pf3xN/N3sSUrPQo2GPPqjQ4wrg5WzLA21rseZIArFXMll9JJ7VR+JxtNXSq5kvg4L96d7EG3ubKhh0TEGjMYy7aRZWsqtu955eucbc6PW3BJ7iQlD+LUGpIpbdqCPxKJxYdfe6Szp/nQlIuBFCCDPSahSmhgXx7IKDt7sONO8NbUG/Fv681i+QoxfTWBUZx6rIeC6mXGfl4ThWHo7D2U5H7yBfBrb0p2uTGtjpKtGHs7mY66rb5qbRgMaKJpCN3l6ycFPS+etMQMKNEEKYWb8W/sx5pA3TV0YRn5plXO7nZs/UsCD6tTBMTaEoCi1rudGylhuv9w8k4nwKqyMNvTjxqVksPXSRpYcu4mKvo0+QH4NC/OncsIbMPn4za77qdlVRmnnpzETCjRBCWEC/Fv70DvJj95kkNmzfS5+uHejYyAdtceeHYwg6ret40LqOB/83oBmHzl9l5eF41hyJJyk9mz8OXuCPgxdwc7ChX3M/Bgb707GhFzZaCTpV8qrb1sQKe8gk3AghhIVoNQod6nty+bhKh/qetw02t9JoFNrW9aRtXU/eHhTE3+eusPpIPGuOJJCckc1v+8/z2/7zeDja0K+FP4OC/elQ3xNddQ46ctXtimVlPWQSboQQohLTaBQ6NPCiQwMvpoY1Z2/0ZVZHxrP2aAJXruXw675Yft0XSw1nW/q18GNQcAD31Ct5kBKixKyoh0zCjRBCVBFajUKnhjXo1LAG0wc3Z88/V1gVGce6YwkkZ+SwYE8sC/bE4uNix4CW/gwM9qdtHQ80EnSEqVhJD5mEGyGEqIJ0Wg1dGtegS+MavDu0BTvPJLM6Mp71xxJISs9m/q5zzN91Dj9Xewa09GdQiD+ta7ujmHpuJyEsQMKNEEJUcTZaDT2a+tCjqQ/vD2vJjjOXWHU4nvCoRBLSsvhhZzQ/7IymprsDA1oaDl0F13KToCMqLQk3QghRjdjqNPQM9KVnoC9ZuflsP53Mqsg4NkYlcjHlOt9tj+a77dHU9nRgYMsABgX70zzAVYKOqFQk3AghRDVlb6Old5AvvYMMQWfLySRWRcaz6XgS569c5+utZ/l661nqeTkyMNifQcEBBPq5SNARVk/CjRBCCOxttPRr4U+/Fv5k5uSx+cQlVkXG8deJJM5dzmT25rPM3nyWBt5ODAo29Og08XWxdNlCFEvCjRBCiEIcbXUMDDacTXUtO4+NxxNZHRnPllOX+OfSNT7fdJrPN52mia8zA1sGMDDYn0Y+zpYuWwgjCTdCCCFuy8lOx5BWNRnSqibpWbnGoLP11CVOJWZwKvEU/9t4ikA/FwbdOHRVr4aTpcsW1ZyEGyGEECXiYm/DsNa1GNa6FqnXcwmPSmRVZBw7TidzIiGdEwnpfLLhFM0DXI2Hrmp7Olq6bFENSbgRQghRam4ONjzQthYPtK3F1Ws5bIhKYFVkPLvOXuZYXBrH4tKYue4EIbXcbhziCqCmu4OlyxbVhIQbIYQQ5eLhZMvIe+ow8p46XM7IZv0xQ4/Onn8uc/hCKocvpPLBmhO0ruPOoOAABrT0w99Ngo6oOBJuhBBCmIyXsx2jOtRhVIc6XErPZt3ReFZFxrPv3BUOxaZwKDaFd1dFcU89Dwa29GdAS398XO0tXbaoYiTcCCGEqBDeLnY82rEej3asR2JaFmuPGILO/pir/H3OcJu+Kor29TwZFBJAv+Z+eLvYWbpsUQVIuBFCCFHhfF3tGde5PuM61yc+9TqrI+NZfSSeQ7Ep7I2+wt7oK0xdfpR7G3gxKDiAfi388HSytXTZopKScCOEEMKs/N0ceKJrA57o2oALVzNZcySe1ZHxHL6Qyq6zl9l19jJvLT9Kp4ZeDAr2p29zP9wdJeiIkpNwI4QQwmJqeTjyVLeGPNWtIbGXM1l9JJ5VkXEci0tj++lktp9O5o2lR+nSuAaDggPoHeSLm4ONpcsWVk7CjRBCCKtQx8uRZ3s05NkeDYlOvsbqyDhWRcZzIiGdLScvseXkJWy1Gro1qcHAYH9Cm/niYi9BRxQl4UYIIYTVqV/DiYk9GzOxZ2POJGWwOtLQo3M6KYONx5PYeDwJW52GHk28jUHHye72H2n5epW90Vc4kKzgFX2Fjo180GpkAtCqSsKNEEIIq9bIx5nJoY2ZHNqYU4nprLoRdP65dI0NUYlsiErETqehZ6APg4IDuC/QG0fbfz/e1h2NZ/rKKOJTswAtP53ej7+bPVPDgujXwt9yL0xUGAk3QgghKo0mvi681NuFF0MbcyIhnVU3Dl3FXM5k7dEE1h5NwMFGS69mPgwK9icnT8/kRRGot2wnITWLZxccZM4jbSTgVEEaS+5827ZthIWFERAQgKIoLFu27I7rx8fHM2rUKJo0aYJGo+GFF14wS51CCCGsi6IoNPN35T99A9nySg9WTerCM90bUsvDgeu5+ayKjOeZBQeLDTaAcdn0lVHk64tbQ1RmFg03165dIyQkhNmzZ5do/ezsbLy9vXnzzTcJCQmp4OqEEEJUBoqi0KKmG6/3D2T7q/exfEJnnuxaHy8nm2KDTQEViE/NYl/0FXOVKszEooel+vfvT//+/Uu8fr169fjss88A+OGHHyqqLCGEEJWUoiiE1HYnpLY7zQPceOG3iLs+JyH1esUXJsyqyo+5yc7OJjs723g/LS0NgNzcXHJzc026r4LtmXq7ojBpZ/OQdjYPaeeKU8OpZB9xU1cc4+9zlxnQwo976nqgkbOoyqWi3tOl2V6VDzczZsxg+vTpRZZv2LABR0fHCtlneHh4hWxXFCbtbB7SzuYh7Wx6ehXcbbWk5AAUF1hUFCAtK4+F+y6wcN8F3GxUWnmptK6hp54zKJJzyszU7+nMzMwSr1vlw82UKVN46aWXjPfT0tKoXbs2ffr0wdXV1aT7ys3NJTw8nN69e2NjIxeWqijSzuYh7Wwe0s4Vy6ZeIpMWHQYoNP5GufHfWSOCcbHXsepIAuHHk0jNymNrgsLWBA0BbvYMaOnHwBZ+NA9wQZGkUyIV9Z4uOPJSElU+3NjZ2WFnV3SWWRsbmwr7Q1KR2xb/knY2D2ln85B2rhiDWtVCp9PedJ0bA79brnPTM8if7Lx8tp9KZlVkHOFRicSlZjF3xznm7jhHPS9HBgb7Myg4gEA/CTolYer3dGm2VeXDjRBCiOqtXwt/egf5sftMEhu276VP1w7FXqHYTqclNMiX0CBfsnLz2XwiiVWR8Ww6kci5y5nM3nyW2ZvP0sjHmUE3gk4jH2cLvSpxJxYNNxkZGZw5c8Z4Pzo6moiICDw9PalTpw5Tpkzh4sWL/PTTT8Z1IiIijM+9dOkSERER2NraEhQUZO7yhRBCVBJajUKH+p5cPq7Sob7nXadesLfR0r+lP/1b+nMtO49NJ5JYeTiOrScvcSYpg1kbTzNr42ma+bsyKNifsOAA6nhVzDhOUXoWDTf79+/nvvvuM94vGBszduxY5s+fT3x8PLGxsYWe07p1a+O/Dxw4wMKFC6lbty7nzp0zS81CCCGqFyc7HYNDAhgcEkBaVi7hxxJZGRnHjtPJHI9P43h8Gh+vP0lwLTfCggMYGOxPgLuDpcuu1iwabnr06IGq3v4SS/Pnzy+y7E7rCyGEEBXJ1d6G4W1rMbxtLa5ey2H9sQRWRcaz62wykRdSibyQyvtrjtO2rgeDgv0Z2NIfH1d7S5dd7ciYGyGEEKIMPJxseah9HR5qX4dL6dmsOxrPysh4/j53hQMxVzkQc5V3VkXRob4ng4ID6N/CDy/noie4CNOTcCOEEEKUk7eLHY92rMejHeuRkJrFmiPxrIyM41BsCnv+ucKef64wdcUxOjX0Iiw4gL7N/XBzlLPjKoqEGyGEEMKE/NzsGd+lPuO71OfC1UxWR8azKjKeIxdT2X46me2nk3lj2RG6NvZmULA/vYN8cbGXoGNKEm6EEEKIClLLw5Gnuzfk6e4NOZd8jVWRcayKjOdEQjp/nUjirxNJ2Oo03NfUm0HBAfRq5oOjrXw0l5e0oBBCCGEG9Wo4MbFnYyb2bMyZpHRWHjYcuvrn0jXWH0tk/bFEHGy09GzmQ1hwAD2aemNvo7V02ZWShBshhBDCzBr5uPBibxdeCG3M8fh0Y49O7BXDYazVkfE42+noHeTLoGB/ujb2xlansXTZlYaEGyGEEMJCFEUhKMCVoABX/tO3KZEXUlkVGcfqyHjiUrNYeugiSw9dxM3Bhr7NfRkUHECnhl7otBJ07kTCjRBCCGEFFEUhpLY7IbXdmdK/GYfOX2Xl4XhWH4nnUno2i/dfYPH+C3g62dK/hR+DggNoX4KrLVdHEm6EEEIIK6PRKLSt60nbup68NSiIfdFXWBUZx9qjCVy5lsMve2P5ZW8s3i52DGzpT1iIP61re6CRoANIuBFCCCGsmlaj0LGhFx0bejF9cHN2nb3Mqsg41h1N4FJ6NvN3nWP+rnMEuNkbZy4PruVWrWcul3AjhBBCVBI6rYZuTbzp1sSb94a2ZPvpS6yKjCc8KpG41Cy+2x7Nd9ujqePpaJy5vJm/S7ULOhJuhBBCiErIVqehVzNfejXzJSs3ny0nL7EqMo5Nx5OIvZLJV1vO8tWWszTwdmJQcABhwf409nWxdNlmIeFGCCGEqOTsbbT0a+FHvxZ+ZObksel4Eqsi49h88hL/XLrG55tO8/mm0wT6uRh7dOrVcLJ02RVGwo0QQghRhTja6ggLCSAsJID0rFzCoxJZFRnP9tOXOJGQzomEdD7ZcIqWNd0MM5cH+1PLw9HSZZuUhBshhBCiinKxt+H+NrW4v00tUjNzWX8sgZWRcew6e5kjF1M5cjGVGWtP0LqOO4OCAxjY0h8/N3tLl11uEm6EEEKIasDN0YYR99RmxD21uZyRzdqjCayKjGNv9BUOxaZwKDaF91ZHcU89T8KC/enf0p8aznaWLrtMJNwIIYQQ1YyXsx2P3FuXR+6tS2JaFmuOGGYuPxBzlX3RV9gXfYWpK47RqWENBgX706+FH+6OtpYuu8Qk3AghhBDVmK+rPY91rs9jnetzMeU6ayINE3pGXkhlx5lkdpxJ5s1lR+nSuAZhwQH0bu6Lq71NsdvK16vsjb7CgWQFr+grdGzkY5ErKEu4EUIIIQQANd0deLJbA57s1oCYy9dYFWno0Tken8aWk5fYcvIStn9q6N7Um0HB/oQ288XJzhAl1h2NZ/rKKOJTswAtP53ej7+bPVPDgujXwt+sr0PCjRBCCCGKqOvlxIT7GjHhvkacScowzlx+JimD8KhEwqMSsbfR0CvQl5ru9ny3PRr1lm0kpGbx7IKDzHmkjVkDjoQbIYQQQtxRIx9nXghtwuRejTmZmM6qw4ZDVzGXM1l9JP62z1MBBZi+MoreQX5mO0Ql4UYIIYQQJaIoCoF+rgT6ufJynyYcvZjGt9vOsjLyzgEnPjWLfdFX6NjQyyx1asyyFyGEEEJUKYqi0LKWG6FBviVaPyk9q4Ir+peEGyGEEEKUmY9LyS76V9L1TEHCjRBCCCHKrH19T/zd7LndaBoF8Hezp319T7PVJOFGCCGEEGWm1ShMDQsCKBJwCu5PDQsy6/VuJNwIIYQQolz6tfBnziNtisxL5edmb/bTwEHOlhJCCCGECfRr4U/vID92n0liw/a99OnaQa5QLIQQQojKTatR6FDfk8vHVTrU97RIsAE5LCWEEEKIKkbCjRBCCCGqFAk3QgghhKhSJNwIIYQQokqRcCOEEEKIKkXCjRBCCCGqFAk3QgghhKhSJNwIIYQQokqRcCOEEEKIKqXaXaFYVVUA0tLSTL7t3NxcMjMzSUtLw8bGxuTbFwbSzuYh7Wwe0s7mI21tHhXVzgWf2wWf43dS7cJNeno6ALVr17ZwJUIIIYQorfT0dNzc3O64jqKWJAJVIXq9nri4OFxcXFAU0855kZaWRu3atTl//jyurq4m3bb4l7SzeUg7m4e0s/lIW5tHRbWzqqqkp6cTEBCARnPnUTXVrudGo9FQq1atCt2Hq6ur/OKYgbSzeUg7m4e0s/lIW5tHRbTz3XpsCsiAYiGEEEJUKRJuhBBCCFGlSLgxITs7O6ZOnYqdnZ2lS6nSpJ3NQ9rZPKSdzUfa2jysoZ2r3YBiIYQQQlRt0nMjhBBCiCpFwo0QQgghqhQJN0IIIYSoUiTcCCGEEKJKkXBTBtu2bSMsLIyAgAAURWHZsmWFHldVlbfffht/f38cHBwIDQ3l9OnTlim2kpoxYwb33HMPLi4u+Pj4MHToUE6ePFlonaysLCZMmICXlxfOzs4MHz6cxMREC1Vcec2ZM4fg4GDjBbc6duzI2rVrjY9LO5vehx9+iKIovPDCC8Zl0s6mMW3aNBRFKXQLDAw0Pi7tbDoXL17kkUcewcvLCwcHB1q2bMn+/fuNj1vys1DCTRlcu3aNkJAQZs+eXezjH330EZ9//jlff/01e/fuxcnJib59+5KVlWXmSiuvrVu3MmHCBPbs2UN4eDi5ubn06dOHa9euGdd58cUXWblyJUuWLGHr1q3ExcVx//33W7DqyqlWrVp8+OGHHDhwgP3799OzZ0+GDBnCsWPHAGlnU/v777/55ptvCA4OLrRc2tl0mjdvTnx8vPG2Y8cO42PSzqZx9epVOnfujI2NDWvXriUqKopPP/0UDw8P4zoW/SxURbkA6tKlS4339Xq96ufnp3788cfGZSkpKaqdnZ3666+/WqDCqiEpKUkF1K1bt6qqamhTGxsbdcmSJcZ1jh8/rgLq7t27LVVmleHh4aHOnTtX2tnE0tPT1caNG6vh4eFq9+7d1cmTJ6uqKu9nU5o6daoaEhJS7GPSzqbz2muvqV26dLnt45b+LJSeGxOLjo4mISGB0NBQ4zI3Nzc6dOjA7t27LVhZ5ZaamgqAp6cnAAcOHCA3N7dQOwcGBlKnTh1p53LIz89n0aJFXLt2jY4dO0o7m9iECRMYOHBgofYEeT+b2unTpwkICKBBgwaMHj2a2NhYQNrZlFasWEG7du148MEH8fHxoXXr1nz33XfGxy39WSjhxsQSEhIA8PX1LbTc19fX+JgoHb1ezwsvvEDnzp1p0aIFYGhnW1tb3N3dC60r7Vw2R44cwdnZGTs7O5555hmWLl1KUFCQtLMJLVq0iIMHDzJjxowij0k7m06HDh2YP38+69atY86cOURHR9O1a1fS09OlnU3on3/+Yc6cOTRu3Jj169fz7LPP8vzzz/Pjjz8Clv8srHazgovKZ8KECRw9erTQcXNhWk2bNiUiIoLU1FR+//13xo4dy9atWy1dVpVx/vx5Jk+eTHh4OPb29pYup0rr37+/8d/BwcF06NCBunXrsnjxYhwcHCxYWdWi1+tp164dH3zwAQCtW7fm6NGjfP3114wdO9bC1UnPjcn5+fkBFBl9n5iYaHxMlNzEiRNZtWoVmzdvplatWsblfn5+5OTkkJKSUmh9aeeysbW1pVGjRrRt25YZM2YQEhLCZ599Ju1sIgcOHCApKYk2bdqg0+nQ6XRs3bqVzz//HJ1Oh6+vr7RzBXF3d6dJkyacOXNG3s8m5O/vT1BQUKFlzZo1Mx4CtPRnoYQbE6tfvz5+fn5s2rTJuCwtLY29e/fSsWNHC1ZWuaiqysSJE1m6dCl//fUX9evXL/R427ZtsbGxKdTOJ0+eJDY2VtrZBPR6PdnZ2dLOJtKrVy+OHDlCRESE8dauXTtGjx5t/Le0c8XIyMjg7Nmz+Pv7y/vZhDp37lzk8hynTp2ibt26gBV8Flb4kOUqKD09XT106JB66NAhFVD/+9//qocOHVJjYmJUVVXVDz/8UHV3d1eXL1+uRkZGqkOGDFHr16+vXr9+3cKVVx7PPvus6ubmpm7ZskWNj4833jIzM43rPPPMM2qdOnXUv/76S92/f7/asWNHtWPHjhasunJ6/fXX1a1bt6rR0dFqZGSk+vrrr6uKoqgbNmxQVVXauaLcfLaUqko7m8rLL7+sbtmyRY2OjlZ37typhoaGqjVq1FCTkpJUVZV2NpV9+/apOp1Off/999XTp0+rv/zyi+ro6KguWLDAuI4lPwsl3JTB5s2bVaDIbezYsaqqGk6Be+utt1RfX1/Vzs5O7dWrl3ry5EnLFl3JFNe+gDpv3jzjOtevX1efe+451cPDQ3V0dFSHDRumxsfHW67oSmr8+PFq3bp1VVtbW9Xb21vt1auXMdioqrRzRbk13Eg7m8bIkSNVf39/1dbWVq1Zs6Y6cuRI9cyZM8bHpZ1NZ+XKlWqLFi1UOzs7NTAwUP32228LPW7Jz0JFVVW14vuHhBBCCCHMQ8bcCCGEEKJKkXAjhBBCiCpFwo0QQgghqhQJN0IIIYSoUiTcCCGEEKJKkXAjhBBCiCpFwo0QQgghqhQJN0IIIYSoUiTcCCGs0qVLl3j22WepU6cOdnZ2+Pn50bdvX3bu3AmAoigsW7bMskUKIaySztIFCCFEcYYPH05OTg4//vgjDRo0IDExkU2bNnH58mVLlyaEsHIy/YIQwuqkpKTg4eHBli1b6N69e5HH69WrR0xMjPF+3bp1OXfuHADLly9n+vTpREVFERAQwNixY3njjTfQ6Qzf5RRF4auvvmLFihVs2bIFf39/PvroIx544AGzvDYhRMWTw1JCCKvj7OyMs7Mzy5YtIzs7u8jjf//9NwDz5s0jPj7eeH/79u2MGTOGyZMnExUVxTfffMP8+fN5//33Cz3/rbfeYvjw4Rw+fJjRo0fz0EMPcfz48Yp/YUIIs5CeGyGEVfrjjz948sknuX79Om3atKF79+489NBDBAcHA4YemKVLlzJ06FDjc0JDQ+nVqxdTpkwxLluwYAGvvvoqcXFxxuc988wzzJkzx7jOvffeS5s2bfjqq6/M8+KEEBVKem6EEFZp+PDhxMXFsWLFCvr168eWLVto06YN8+fPv+1zDh8+zDvvvGPs+XF2dubJJ58kPj6ezMxM43odO3Ys9LyOHTtKz40QVYgMKBZCWC17e3t69+5N7969eeutt3jiiSeYOnUq48aNK3b9jIwMpk+fzv3331/stoQQ1YP03AghKo2goCCuXbsGgI2NDfn5+YUeb9OmDSdPnqRRo0ZFbhrNv3/u9uzZU+h5e/bsoVmzZhX/AoQQZiE9N0IIq3P58mUefPBBxo8fT3BwMC4uLuzfv5+PPvqIIUOGAIYzpjZt2kTnzp2xs7PDw8ODt99+m0GDBlGnTh0eeOABNBoNhw8f5ujRo7z33nvG7S9ZsoR27drRpUsXfvnlF/bt28f3339vqZcrhDAxGVAshLA62dnZTJs2jQ0bNnD27Flyc3OpXbs2Dz74IP/3f/+Hg4MDK1eu5KWXXuLcuXPUrFnTeCr4+vXreeeddzh06BA2NjYEBgbyxBNP8OSTTwKGAcWzZ89m2bJlbNu2DX9/f2bOnMmIESMs+IqFEKYk4UYIUa0Ud5aVEKJqkTE3QgghhKhSJNwIIYQQokqRAcVCiGpFjsQLUfVJz40QQgghqhQJN0IIIYSoUiTcCCGEEKJKkXAjhBBCiCpFwo0QQgghqhQJN0IIIYSoUiTcCCGEEKJKkXAjhBBCiCpFwo0QQgghqpT/Bxd+q2S4NaHLAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating Sample"
      ],
      "metadata": {
        "id": "V9TtcXCHsoSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example prompts for testing\n",
        "test_prompts = [\n",
        "    \"Explain overfitting in machine learning.\",\n",
        "    \"List three benefits of unit testing.\",\n",
        "    \"What is regularization and why is it useful?\",\n",
        "]\n",
        "\n",
        "for prompt in test_prompts:\n",
        "    inputs = tokenizer(f\"### Instruction:\\n{prompt}\\n\\n### Response:\\n\", return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=128,\n",
        "            temperature=0.7,\n",
        "            top_p=0.9,\n",
        "            do_sample=True\n",
        "        )\n",
        "    print(f\"Prompt: {prompt}\\nResponse: {tokenizer.decode(outputs[0], skip_special_tokens=True)}\\n{'-'*40}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCx--96Orxbj",
        "outputId": "772b969b-4b02-4bd1-9e8e-5f5a58b3760f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Explain overfitting in machine learning.\n",
            "Response: ### Instruction:\n",
            "Explain overfitting in machine learning.\n",
            "\n",
            "### Response:\n",
            "Overfitting is a phenomenon that occurs when a model is too complex for the data it is trained on. As a result, the model starts to learn the noise in the data instead of the underlying structure. This can lead to a model that performs well on training data but poorly on test data. To prevent overfitting, machine learning algorithms use regularization techniques such as weight decay and dropout. These techniques help to reduce the complexity of the model, preventing it from overfitting on the training data.\n",
            "----------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: List three benefits of unit testing.\n",
            "Response: ### Instruction:\n",
            "List three benefits of unit testing.\n",
            "\n",
            "### Response:\n",
            "Unit testing helps to identify and fix bugs before they reach the user, ensures code is well-written and easy to maintain, and provides a foundation for future development.\n",
            "Unit testing is a process of testing small units of code to ensure they are working correctly. It is a fundamental part of software development and is used to identify and fix bugs, ensure code is well-written and easy to maintain, and provide a foundation for future development.\n",
            "Unit testing can help to identify and fix bugs before they reach the user. This can save time and money as it reduces the need for costly fixes and can improve the overall quality of the\n",
            "----------------------------------------\n",
            "Prompt: What is regularization and why is it useful?\n",
            "Response: ### Instruction:\n",
            "What is regularization and why is it useful?\n",
            "\n",
            "### Response:\n",
            "Regularization is a technique used in machine learning to prevent overfitting by penalizing the model for overly complex solutions. Regularization helps to generalize the model by reducing the number of parameters and thus making it more robust to noise and unseen data. Regularization can also help to prevent overfitting by reducing the variance of the model's predictions.\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "zip_path = \"/content/mistral-7b-qlora-alpaca.zip\"\n",
        "shutil.make_archive(\"/content/mistral-7b-qlora-alpaca\", 'zip', \"/content\")\n",
        "print(f\"Zipped file saved at: {zip_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3xnz8wnrsFF",
        "outputId": "a8399ff6-759a-4bfc-d95e-aeb4f0750878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zipped file saved at: /content/mistral-7b-qlora-alpaca.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "06Sygga5ZnDq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}